---
title: "R package for precision medicine<br> count outcome" 
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  rmarkdown::html_vignette:
    toc: TRUE
    number_sections: TRUE
    toc_depth: 3
    fig_caption: yes
    fig_width: 9
    fig_height: 6
    bookdown::html_document2: default
bibliography: assets/references.bib
link-citations: yes
theme: lumen
vignette: >
 %\VignetteIndexEntry{R package for precision medicine - count outcome}
 %\VignetteEngine{knitr::knitr}
 \usepackage[utf8]{inputenc}
---

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("assets/sticker4.jpg"), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:10px; padding:0px;',
               width = "300px",
               heigth = "300px")
```


# Introduction
**PrecMed** provides a workflow for estimating and internally validating conditional average treatment effects (CATEs) from either randomized controlled trials (RCTs) or real-world data between 2 treatments. The CATE score, also known as the individualized treatment response score, is a continuous scalar for each subject which represents an expected individual-level treatment contrast, e.g., a difference or ratio of potential outcomes. It is used to explore *treatment effect heterogeneity* by distinguishing between potential subgroups with different average treatment effect (ATE). The CATE score can be estimated using various scoring methods depending on the type of outcome. `PrecMed` has 3 built-in validation metrics (area between curves [ABC], validation curves, and box plots) to internally evaluate the performance of different scoring methods with repeated cross-validation (CV).

`PrecMed` accepts count and survival outcomes only, and this vignette focuses on count outcomes. As common for count data, the CATE is expressed as a ratio of expected rate of events or rate ratio (RR). Five methods have been implemented to calculate the CATE scores for count outcomes: boosting, Poisson, negative binomial, two regressions, and contrast regression (@yadlowsky2020estimation). Two and contrast regressions are doubly robust estimation methods which leverage estimation of the propensity score (PS), whereas the 3 other methods are naive plug-in methods where the outcome is predicted based on separate models trained in each treatment arm. Extensions to continuous and longitudinal outcomes are work-in-progress, as well as extensions to more than 2 treatments. Stay tuned.  

The main functions of the package are: `pm()`, `cv()`, `abc()`, `plot()`, `boxplot()`, `dr.inference()`. The recommended workflow of analyses to identify treatment effect heterogeneity with several candidate scoring methods follows the steps below:

1. Compare up to 5 methods to construct the CATE score via internal validation (function `cv()`).  

2. Select the best method using 3 metrics:

    2.1 Compare the ABC across methods (function `abc()`).
  
    2.2 Compare the steepness of the validation curves in the validation samples across methods (function `plot()`).
  
    2.3 Compare the distribution of the ATE in mutually exclusive subgroups in the validation samples (function `boxplot()`).
  
  
3. For the selected method, estimate the CATE score in the entire data or, ideally, in an external data set (function `pm()`). Steps 1 & 2 can be skipped if comparing and selecting methods are not of interest.  

4. Optional. Use `dr.inference()` to estimate ATE between 2 treatment groups with a doubly robust estimator and estimate the variability of the ATE with a bootstrap approach. 


This vignette has 3 main sections:

1. [Examples](#examples): Practical demonstration of `PrecMed` with a built-in toy example

2. [Function description](#fundescr): Detailed descriptions of the function, usage, arguments, returned values, and references

3. [Theoretical details](#theodetail): Theoretical background of the scoring method as well as the estimation of CATE and ATE

All abbreviations used in this vignette can be found in the [Abbreviations](#abbrev) section.

  
# Abbreviations {#abbrev}

Abbreviation        Full Name
-------------       ----------
ABC                 Area between curves
ATE                 Average treatment effect
CATE                Conditional average treatment effect
contrastReg         Contrast regression
CV                  Cross-validation
GAM                 Generalized additive model
GBM                 Gradient boosting machine
IPCW                Inverse probability of censoring weights
PM                  Precision medicine
PS                  Propensity score 
RCT                 Randomized controlled trial
RR                  Rate ratio
twoReg              Two regressions

# Main example of the entire workflow {#examples}
```{r setup, include=FALSE}
###################################################################
#
# Project: Comprehensive R package for precision medicine
#
#
# Objective: Demonstrate the main features of the count outcome functions
#
#
# Contributors: Phoebe Jiang, Gabrielle Simoneau
#
#
# Modifications:
#
#   Date			By			Description
# --------		--------	-----------------------------
#  01FEB2021  gs      Start the script
#  04FEB2021  pj      Add some new sections and make some modification
#  05FEB2021  pj      Rename the cv.pmcount to cvcount
#  28APR2021  pj      Revise the cv and pm functions after improvements since Feb 17
#  MAY2021    pj/gs   Revise the documentation and description of each function
#  JUN2021    pj/gs   Revise the example section with explanations of the workflow and outputs
#  14SEP2021  gs      Revise documentation and example after removing 2 outputs in cvcount()
#  19NOV2021  gs      Update cvcount() output and default y-axis in plot and boxplot
#  13DEC2021  gs      Rename one output of cvcount()
#  30MAY2022  gs      Update cv, pm, plot, boxplot, abc (more TODO) based on new functions
#  08JUN2022  gs      Minor edits
#  17JUN2022  gs      Add dr.inference
#  07JUL2022  gs      Update cv documentation
#  11JUL2022  gs      Added fgam output to cvcount
#  13JUL2022  gs      Update pm function description
#  22JUL2022  gs      Add drinf function description
#  27JUL2022  pj      Minor edits
###################################################################

options(mc.cores = 2) # R CMD check allows at most two cores
knitr::opts_chunk$set(echo = TRUE)
library(PrecMed)
library(ggplot2)
library(dplyr)
```

## Example data set

We use the following simulated data to demonstrate the `PrecMed` functions for count outcomes. The data set `countExample` was simulated based on real-world claims data in multiple sclerosis and has 4,000 observations and 9 variables. 

* We will use `y` as the count outcome, which is the number of relapses during follow-up. 

* We will use `years` as the offset variable, which is number of years during follow-up.

* We will use `trt` as the treatment variable, which has 2 drugs (drug0 and drug1). 

* The rest of the variables are baseline patient characteristics. Variable `age` is centered at 48 years old. The medical costs in the year prior to treatment initiation `previous_cost` is centered at 13,824 USD and scaled with standard deviation 20,172 USD.

```{r data, echo = F, eval = T, include = T}
str(countExample)
```

## Installation

<!-- TODO: change it to CRAN or github later. -->

```{r install, echo = T, eval = F}
library(devtools)
# install.packages(".../PrecMed_0.1.2.tar.gz", repos = NULL)
install.packages("C:/Users/gsimonea/OneDrive - Biogen/Desktop/PrecMed_0.1.2.tar.gz", repos = NULL)
```

## Internal validation via `cv()` {#cvcountexample}

We first run the internal validation to compare 5 scoring methods. This is done with the function `cv()`. This first step gives results in the form of a "PrecMed" object which will be used in the next steps to compare the performance of the scoring methods.

The mandatory arguments in `cv()` are `response`, `cate.model`, `ps.model`, `data`, and `score.method`. They must be specified by the user. 

* The `response` argument specifies the type of outcome in the data. For count outcomes, `response` = "count". This informs the function of the necessary arguments and methods to use. 

* The argument `cate.model` specifies the CATE model as a formula, with the outcome `y` supplied on the left-hand side and the explanatory covariates supplied on the right-hand side. In the example, we choose to specify to CATE as a linear combination of the following covariates: age, sex, previous treatment, medical costs in the year prior to treatment initiation, and number of relapses in the year prior to treatment initiation. Non-linear or interaction terms could also be included. The CATE model has the offset `log(years)` to account for the varying exposure times across patients. Note that the treatment variable is not supplied in `cate.model` since this is an outcome model.

<!-- * We use all 6 variables in the outcome CATE model and specify the offset as `log(years)`. It is recommended to log-transform the exposure variable.
* -->

* The `ps.model` argument specifies the PS model as a formula, with the treatment variable `trt` on the left-hand side and the covariates (age and previous treatment in this example) on the right-hand side. The variable `trt` must be supplied as a numeric variable taking only 2 values, 1 for active treatment and 0 for control or comparator. If it is not the case, `cvcount()`  will stop with error if  `trt` takes more than 2 distinct values or will automatically transform `trt` into a numeric variable. In this example, `trt` (a factor variable taking values "drug0" and "drug1") was transformed and a warning message was left to the user (see output below): `Variable trt was recoded to 0/1 with drug0->0 and drug1->1`. If the data are from a RCT, it suffices to specify `ps.model` = trt ~ 1. Note that the PS model is only used in the estimation of the 2 doubly robust methods (two and contrast regressions).

* The argument `data` indicates the data frame in which the outcome, treatment and covariates specified in either `cate.model` or `ps.model` should be fetched.

* The `score.method` argument specifies the precision medicine (PM) methods to be used to calculate the CATE scores. There are a total of 5 scoring methods implemented:

  * `poisson` fits a Poisson model separately by treatment group.
  
  * `boosting` uses gradient boosted regression models (GBM) separately by treatment group.
  
  * `twoReg` implements the doubly robust two regressions estimator in @yadlowsky2020estimation.
  
  * `contrastReg` implements the doubly robust contrast regression estimator from @yadlowsky2020estimation.
  
  * `negBin` fits negative binomial regressions by treatment group. This method is recommended if there is overdispersion in the data.

We also specified the following non-mandatory arguments to fit with the data and problem at hand: `higher.y`, `initial.predictor.method`, `cv.n`, `plot.gbmperf`, and `seed`.

* `higher.y` was set to FALSE because lower number of relapses are more desirable in our example. Hence, we are telling the function that subgroups of high responders to drug1 vs drug0 should have lower number of relapses  (see section [Validation curves and the ABC statistics](#ABCdetails) for illustration). In other situation, higher outcomes may be more favorable, for example, walking more steps in a study on physical activity. It is important for this argument to match with the `y` outcome because it will affect how the subgroups are defined by the CATE scores and the performance metrics. 

* `initial.predictor.method` specifies how predictions of the outcome are estimated in two regressions and contrast regression. Flexible models can be used such as GBM ("boosting") or generalized additive models ("gam"). Both methods are computationally intensive so we choose "poisson" to obtain predictions from a Poisson regression, which reduces the computational time at the expense of stricter parametric assumptions and less flexibility.

* We perform 5 CV iterations by specifying `cv.n` = 5. Typically, more CV iterations are desirable although associated with longer computational times.

* We avoid generating the boosting performance plots by specifying `plot.gbmperf` = FALSE.

* We set a random seed `seed` = 999 to reproduce the results.

* There are many other non-mandatory arguments that `cv()` can accept. Please see the [More Examples](#moreexamples) section for more examples and the [Function description](#cvcountdescr) section for details. If you run into errors or warnings with your data, it might be helpful to go over the descriptions to see if you need to alter the default values. In this toy example, we keep the default values of the remaining arguments.

```{r example_cv, eval = T, echo = T}
t0 <- Sys.time()
output_cv <- cv(response = "count",
                cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses 
                                + offset(log(years)),
                ps.model = trt ~ age + previous_treatment, 
                data = countExample,
                higher.y = FALSE,
                score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
                initial.predictor.method = "poisson", 
                cv.n = 5, 
                plot.gbmperf = FALSE,
                seed = 999 #, 
                # n.cores = 2
                )
t1 <- Sys.time()
t1 - t0
```


When `verbose` = 2 (default), progress messages and warning/errors (if any) are printed in the R console. The current CV iteration is printed, followed by the steps of the CV procedure (splitting the data, training the models, validating the models) and warnings or errors that have occurred during the steps (none in this example). A timestamp and a progress bar are also displayed upon completion of a CV iteration. If `contrastReg` was selected as one of the methods in `score.method`, an additional line of output message will indicate whether the algorithm has converged.

The output of `cv()` is an object of class "PrecMed" and here we named it `output_cv`. It carries the relevant information to use in the next step of the workflow which selects the method (among those specified in the argument `score.method`) capturing the highest level of treatment effect heterogeneity. The output, which is described below, will be used in the functions `plot()`,`boxplot()` and `abc()`.

For each method specified in the argument `score.method`, the following 4 groups of outputs are generated. We use the results from `contrastReg` as an example.

**1\. ATEs in nested subgroups of high responders**

This output stores the ATEs - the ratio of annualized relapse rate between drug1 vs drug0 in this example - in nested subgroups of patients of high responders to drug 1 in the training (`$ate.est.train.high.cv`) and validation (`$ate.est.valid.high.cv`) sets across all CV iterations. For count outcomes, When `higher.y` = TRUE, higher CATE scores correspond to high responders to drug1. When `higher.y` = FALSE, lower CATE scores correspond to high responders to drug1. Note that this is different for survival outcomes. The direction of CATE scores depends on both `higher.y` and outcome type. 


```{r example_print_cv, eval = T, echo = T}
output_cv$ate.contrastReg$ate.est.train.high.cv
```

The output is a matrix with columns corresponding to the CV iterations, labeled from 1 to `cv.n`, and rows corresponding to nested subgroups. The nested subgroups of patients are defined by the argument `prop.cutoff`. Here, we use the default `seq(0.5, 1, length = 6)` which defines 6 nested subgroups with the 50\%, 60\%, 70\%, 80\%, 90\% and 100\% lowest (highest if `higher.y` = TRUE) CATE scores estimated by contrast regression. The rows in the output are labeled to reflect the user-specified proportions used to build the subgroups.

For example, in the training set and in the first CV iterations (first column labeled "cv1"), the subgroup defined with the 50\% lowest CATE scores (first row labeled "prop0.5") has an estimated RR of `r round(output_cv$ate.contrastReg$ate.est.train.high.cv[1,1], 3)`. In contrast, the subgroup defined with all patients (last row labeled "prop1") has an estimated RR of `r round(output_cv$ate.contrastReg$ate.est.train.high.cv[6,1], 3)`. <!-- This suggests that the CATE score estimated with contrast regression identifies high responders to drug 1 vs drug 0 because patients with the 50\% lowest estimated CATE score have a better (lower) RR compared to all patients. However, the same relationship between estimated RRs is not observed in the training set. This will be further visualized with valiation curves in the next section. 
If higher outcomes were preferable (as specified through the argument `higher.y`), subgroups would be defined with proportion of patients with *highest* estimated CATE score and *higher* RR would be better. -->

**2\. ATEs in nested subgroups of low responders**

This output stores the ATEs in nested subgroups of *low responders* to drug1 in the training (`$ate.est.train.low.cv`) and validation (`$ate.est.valid.low.cv`) sets across all CV iterations. For count outcomes, when `higher.y` = TRUE, lower CATE scores correspond to low responders to drug1. When `higher.y` = FALSE, higher CATE scores correspond to low responders to drug1. Again, this is different for survival outcomes. The direction of CATE scores depends on both `higher.y` and outcome type. 

```{r example_print_train_cv, eval = T, echo = T}
output_cv$ate.contrastReg$ate.est.train.low.cv
```
The outputs are also matrices with columns corresponding to the CV iterations and rows corresponding to nested subgroups. 

The output for the low responders brings additional information to the user. It gives the ATEs in the complement of each nested subgroup of high responders. For example, the complement of the subgroup of high responders defined as patients with the 60\% lowest (highest if `higher.y` = TRUE) estimated CATE scores is the subgroup low responders defined as patients with the 40\% highest (lowest if `higher.y` = TRUE) estimated CATE scores, labeled as "prop0.4". In the training set and in the first CV iterations, the estimated RR is `r round(output_cv$ate.contrastReg$ate.est.train.high.cv[2,1], 3)` in the 60\% high responders to drug 1 and `r round(output_cv$ate.contrastReg$ate.est.train.low.cv[2,1], 3)` in the 40\% low responders.

**3\. ATEs in mutually exclusive subgroups**

This output stores the ATEs in mutually exclusive multi-category subgroups of patients in the training (`$ate.est.train.group.cv`) and validation (`$ate.est.valid.group.cv`) sets across all CV iterations. 

```{r example_print_group_cv, eval = T, echo = T}
output_cv$ate.contrastReg$ate.est.train.group.cv
```

The output is a matrix with columns corresponding to the CV iterations and rows corresponding to the mutually exclusive subgroups. The previous 2 outputs only focus on binary subgroups (high or low responders). Here, the mutually exclusive subgroups can be more than 2 and are defined by the argument `prop.multi`. We use the default `c(0, 1/3, 2/3, 1)` which defines 3 subgroups of patients with the 33\% lowest, 33\% middle and 33\% highest estimated CATE scores when `higher.y` = FALSE (as in this example), or with the 33\% highest, 33\% middle and 33\% lowest estimated CATE scores when `higher.y` = FALSE. Taking the first column as an example, the first CV iteration calculated `r round(output_cv$ate.contrastReg$ate.est.train.group.cv[1,1], 3)` as the RR for the subgroup with the 33\% lowest estimated CATE scores, `r round(output_cv$ate.contrastReg$ate.est.train.group.cv[2,1], 3)` as the RR for subgroup with the 33\% middle estimated CATE scores, and `r round(output_cv$ate.contrastReg$ate.est.train.group.cv[3,1], 3)` as the RR for subgroup with the 33\% highest estimated CATE scores.


## Comparison of methods with `abc()`

The ABC statistics is calculated by `abc()` for each scoring method specified in `cv()` and for each of the `cv.n` CV iterations using the output object `output_cv` from `cv()`. The ABC corresponds to the area between the curve formed by the ATEs in subgroups of high responders in the validation set (e.g., `output_cv$ate.contrastReg$ate.est.valid.cv` for contrast regression) and the horizontal line representing the ATE in the validation set. A higher ABC value means that the method captures more treatment effect heterogeneity. See the [Validation curves and the ABC statistics](#ABCdetails) section for a detailed illustration of the relationship between `higher.y`, `abc`, and the validation curves. 

```{r example_abc, eval = T, echo = T}
output_abc <- abc(x = output_cv)
output_abc
```

The output is a matrix with columns corresponding to the CV iterations and rows corresponding to the scoring methods specified in `score.method`. For example, in CV iteration 1, negative binomial ("negBin") has an ABC of `r round(output_abc[5,1], 3)`, which is the highest in this CV iteration, meaning that negative binomial offers the best performance in the first CV iteration. The user can combine the ABC for each method across iterations:

```{r example_abc_combine, eval = T, echo = T}
average_abc <- apply(output_abc, 1, mean)
average_abc
```
In this example, negative binomial also offers the best overall performance because it has the highest average ABC, followed closely by Poisson.

## Visualization of the validation curves with `plot()`

The ATEs of nested subgroups of high responders to drug1 (e.g., `output_cv$ate.contrastReg$ate.est.train.high.cv` and `output_cv$ate.contrastReg$ate.est.valid.high.cv` for contrast regression) can be visualized as a side-by-side line plot, with training results on the left and validation results on the right. The x-axis is determined by `prop.cutoff` and the y-axis is the estimated ATEs averaged over `cv.n` CV iterations as specified by `cv.i` = NULL. The estimated ATE is expressed as a RR of drug1 versus drug0 for our toy example. By default, the function retrieves the name of the treatment variable (`trt`) and the original labels (`drug0` and `drug1`) to specify a meaningful y-axis label. Otherwise, it is possible to customize the y-axis label via the `ylab`, for example, by using `Rate ratio of drug1 vs drug0 in each subgroup`. 

Steeper slopes indicate more treatment effect heterogeneity between drug1 and drug0. Because `higher.y` = FALSE in this example, the slopes should be increasing from left (`prop.cutoff` = 0.5) to right (`prop.cutoff` = 1) if treatment effect heterogeneity is present. The method that has the steepest slope in the validation results would be selected because it captures the most treatment effect heterogeneity while generalizing well to unseen data.

 
```{r example_plot_lineplot1, eval = T, echo = T}
plot(x = output_cv)
```

For this toy example, the methods are performing well in the training data as per the steep, increasing slopes on the left plot. Moreover, all methods generalize well to the validation data, as indicated by the monotonous increasing curves in the validation data (right plot). The dashed gray line is the ATE in the entire data set, which is why all lines merge to this reference line when subgroup size is 100\% of the data (`prop.cutoff` = 1). For more explanation on the validation curves, see the [Function description](#plotdescr) section. 

The  plot's legend includes the ABC statistics in the validation set. The user can choose to mute the ABC annotations by specifying `show.abc` = FALSE.

```{r example_plot_lineplot1.1, eval = T, echo = T}
plot(x = output_cv, 
     show.abc = FALSE, 
     ylab = c("Rate ratio of drug1 vs drug0 in each subgroup"))
```

The user can choose to plot the validation curves of only one CV iteration instead of the average of all CV iterations. In the following example, we plot the validation curves of the second CV iteration by specifying `cv.i` = 2 and in grayscale by specifying `grayscale` = TRUE.

```{r example_plot_lineplot2, eval = T, echo = T}
plot(x = output_cv, 
     cv.i = 2, 
     grayscale = TRUE, 
     ylab = c("Rate ratio of drug1 vs drug0 in each subgroup"))
```

Same as `abc()`, the user can also choose to use the median (instead of mean [default]) of the ATEs across CV iterations by specifying the argument `combine` = "median" in `plot()`. 

## Visualization of the ATE in subgroups with `boxplot()` 

The ATEs of multi-category subgroups that are mutually exclusive can be visualized as box plots, with one box plot for each scoring method. Only validation results are visualized here. The x-axis is determined by `prop.multi` and the y-axis is the estimated ATEs in each subgroup. We specify the `ylab` argument accordingly. The subgroups correspond to each row of the `ate.est.valid.group.cv` result in `output_cv`, so in this example the subgroups are patient with the 33\% lowest (0-33\%), middle 33\% (33-66\%), and highest 33\% (66-100\%) estimated CATE scores. The box plot shows the distribution of the ATEs over all `cv.n` CV iterations, instead of a summary statistics like mean or median in `plot()`. 

```{r example_plot_boxplot, eval = T, echo = T}
boxplot(x = output_cv,
        ylab = "Rate ratio of drug1 vs drug0 in each subgroup")
```

For this toy example, we can see why the two regressions method has the highest ABC and performs the best in the validation curves in the previous sections. Two regression has a decreasing RR as we go from the subgroup  with the 33\% lowest CATE scores (0-33\%) to subgroup with the 33\% highest CATE scores (66-100\%), implying that there is some evidence of heterogeneous treatment effect and the CATE scores estimated with two regressions can distinguish the treatment heterogeneity in the data. In comparison, the other 3 methods seem to struggle with the validation data. Even tough they show different subgroups, we can see that the box plots correspond to the other 2 metrics. Note that the y-axis can have different scales for different scoring methods.

<br><br>

> Although we provided 3 different metrics to summarize and visualize the `cv()` outputs, the user is encouraged to choose their own way of data wrangling that fits to their particular situation. 

<br><br>

## Estimation of the CATE score with `pm()` 

If no internal validation is needed or the user has chosen the scoring methods wanted, we can fit the PM methods directly to the entire data set to estimate the CATE score. The ATE by subgroup defined by `prop.cutoff` can also be retrieved. This is done with the function `pm()`. 

In general, `pm()` has similar arguments as `cv()`. The mandatory arguments are the same: `response`, `cate.model`, `ps.model`, `data`, and `score.method`, and they must be specified by the user. The user can also specify the non-mandatory arguments to fit with the data and problem at hand. Please see the [Function description](#pmcountdescr) section for details. Because there is no internal validation, `pm()` does not have the `cv.n`, `train.prop`, `abc`, and `prop.multi` arguments. This is the main distinction between these 2 output functions. We specified the mandatory and non-mandatory arguments the same way as `cv()` in the example for demonstration purpose. 

If you run into errors or warnings with your data, it might be helpful to go over the descriptions to see if you need to alter the default values. In this toy example, we keep the default values of the remaining arguments.


```{r example_pm, eval = T, echo = T}
# Apply pmcount
t0 <- Sys.time()
output_pm <- pm(response = "count",
                cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses 
                                + offset(log(years)),
                ps.model = trt ~ age + previous_treatment,
                data = countExample,
                higher.y = FALSE,
                score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
                initial.predictor.method = "poisson",
                seed = 999 #,
                #n.cores = 2
                )
t1 <- Sys.time()
t1 - t0
```

Despite the similar arguments, the outputs of `pm()` and `cv()` differ. Each method specified in `score.method` has the following sets of results in `pm()`: 

1. `score` contains the log-transformed estimated CATE scores for each subject. CATE score is a linear combination of the variables specified in the `cate.model` argument. Same as the outcome, lower CATE scores are more desirable if `higher.y` = FALSE and vice versa. Each subject has one CATE score so the length of this output is 4,000 for our toy example. Below we show the CATE scores estimated with contrast regression for the first 6 subjects in the data. 

```{r print_pm.score, eval = T, echo = T}
length(output_pm$score.contrastReg)
head(output_pm$score.contrastReg)
```

2. `coefficients` contains the estimated coefficients of the CATE score for each scoring method. It is a data frame of the covariates (including intercept) as rows and scoring methods as columns. In our toy example, there are 5 covariates in the `cate.model` (including a categorical variable with 3 distinct factors) so there are 7 rows of estimated coefficients within each column. Since contrast regression is one of the scoring methods specified in the example, we see that contrast regression has an additional column with the standard errors of the estimated coefficients. Boosting does not estimate coefficients (it directly predicts the score) so there is no coefficient result for this method.

```{r print_pm.coefs, eval = T, echo = T}
output_pm$coefficients
```

We can define the estimated CATE scores for contrast regression like shown below. The user can use this information to study the influence of each covariate. 
$$ 
\begin{aligned}
\widehat{CATE} = -0.60 & - 0.04 \times \text{age} \\
& + 0.77 \times \text{female (vs male)} \\ 
& + 0.75 \times \text{previous treatment drug B (vs drug A)} \\
& - 0.21 \times \text{previous treatment drug C (vs drug A)} \\
& - 0.02 \times \text{previous medical costs} \\
& + 0.04 \times \text{previous number of relapses} 
\end{aligned} $$

3. `ate` contains estimated ATEs in each nested subgroup of high responders to drug 1 defined by `prop.cutoff`. The subgroups are defined based on the estimated CATE scores with the specified scoring method. In this example, we show the estimated ATEs of subgroups identified by CATE scores of contrast regression. For example, the estimated ATE for the subgroup of subjects constructed based on the 50\% ("prop0.5") lowest CATE scores estimated from contrast regression is `r round(output_pm$ate.contrastReg[1], 2)`. 

```{r print_pm.ate, eval = T, echo = T}
output_pm$ate.contrastReg
```
You are encouraged to summarize and visualize the outputs in whichever way that fits a particular situation outside the package's functions. For example, it is possible to plot the densities of all CATE scores with `ggplot()`. There are some subjects with extremely low CATE scores but most of the samples fall between -1 and 1 with triple modes at around -0.5, 0, and 0.8. 

```{r plot_score, eval = T, echo = T, fig.align='center'}
dataplot <- data.frame(score = factor(rep(c("Boosting", "Naive Poisson", "Two regressions", "Contrast regression", "Negative Binomial"), each = length(output_pm$score.boosting))), 
                       value = c(output_pm$score.boosting, output_pm$score.poisson, output_pm$score.twoReg, output_pm$score.contrastReg, output_pm$score.negBin))

dataplot %>% 
  ggplot(aes(x = value, fill = score)) + 
  geom_density(alpha = 0.5) +
  theme_classic() + 
  labs(x = "Estimated CATE score", y = "Density", fill = "Method")
```


## Estimation of the ATE with `dr.inference()` 

Beyond exploring treatment effect heterogeneity, `dr.inference()` allows estimating the ATE in terms of rate ratio. The rate ratio estimator is doubly robust, meaning that the estimator is consistent if the PS model (argument `ps.model`) or the outcome model (argument `cate.model`) or both are correctly specified. The function also provides standard error, confidence intervals, and p-values based on bootstrap.

The mandatory arguments are: `response`, `cate.model`, `ps.model`, and `data`. Those arguments have the same definitions as in `cv()` and `pm()`.

```{r run_dr.inference, eval = T, echo = T}
output_dr <- dr.inference(response = "count",
                          cate.model = y ~ age + female + previous_treatment + previous_cost 
                                         + previous_number_relapses + offset(log(years)),
                          ps.model = trt ~ age + previous_treatment,
                          data = countExample,
                          n.boot = 500, verbose = 1, 
                          plot.boot = FALSE, seed = 999)
```

When `verbose` = 1, the function outputs 10 times the number of bootstrap iterations completed in the console. Since `n.boot` = 500, the number of bootstrap iterations are shown as a multiple of 50 in the example code.

```{r print_dr.inference, eval = T, echo = T}
output_dr
```

The output of `dr.inference()` shows the point estimate, standard error ("SE"), lower ("CI.lower") and upper ("CI.upper") bound of the 95\% confidence interval, and the p-value ("pvalue") for the log rate ratio (`$log.rate.ratio`) as well as the point estimate for the rate in the 2 treatment groups (`$rate0` and `$rate1`). For example, the log rate ratio of `r round(output_dr$log.rate.ratio$estimate, 2)` and the 95\% confidence interval of (`r round(output_dr$log.rate.ratio$CI.lower, 2)`, `r round(output_dr$log.rate.ratio$CI.upper, 2)`) are displayed in the output. The user can retrieve the rate ratio to facilitate the interpretation:

```{r rmtl_dr.inference, eval = T, echo = T}
rate.ratio <- exp(output_dr$log.rate.ratio$estimate)
rate.ratio
CI.rate.ratio <- exp(output_dr$log.rate.ratio$estimate + c(-1, 1) * qnorm(0.975) * sqrt(output_dr$log.rate.ratio$SE))
CI.rate.ratio
```

The rate ratio of `r round(rate.ratio, 2)` along with the 95\% confidence interval of (`r round(CI.rate.ratio[1], 2)`, `r round(CI.rate.ratio[2], 2)`) suggest that drug 0 is superior to drug 1 because the ratio is greater than 1 and lower outcomes are preferred, but that this superiority is not statistically significant given the p-value of `r round(output_dr$log.rate.ratio$pvalue, 2)` in the output (`$log.rate.ratio$pvalue`).

The output of `dr.inference()` is expressed in terms of treatment 0 vs 1 and the rate ratio is expressed as the ratio of the treatment coded as 1 over the treatment coded as 0. If the treatment variable is not coded as 0/1 in the data set, the function returns a warning `output_dr$warning` which indicates which key was used to recode the treatment variable into a 0/1 variable.

```{r warning_dr.inference, eval = T, echo = T}
output_dr$warning
```

When `plot.boot` = TRUE, the output provides histograms `$plot` of the point estimates across the `n.boot` bootstrap iterations for the log rate ratio. A red vertical line is added to each histogram with the mean of the bootstrap estimates. Moreover, when `plot.boot` = TRUE and `verbose` = 1, the histogram is displayed in the console and updated at each 10\% bootstrap iteration. For example, when `n.boot` = 500, the updated histogram is shown every 50 bootstrap iterations.

![Figure. Histograms of bootstrap log rate ratio estimators after 500 bootstrap iterations, produced if `plot.boot` = TRUE](assets/drinference_bootstrap_count.png)


# More examples {#moreexamples}
**PrecMed** can be flexible given the many arguments that the user can specify. The example described above is one of the many ways to perform the analysis with most argument values kept as default. We provide a few more examples below to show what other options the user has and how to be more creative in using **PrecMed**. 

## Initial predictor method
If you choose two regressions or contrast regression as the scoring method, there is an option to specify how the initial outcome regression estimates ($\hat\mu_r^k$ where $r = 0,1$ is the treatment and $k$ is the CV fold) are calculated. See [Theoretical details](#theodetail) section for the background of these initial predictors and how they are used in two and contrast regressions. Here is a list of all 3 options:

* "poisson" (Poisson regression from the `glm()` function) 
  * generalized linear model, strong assumption on Poisson distribution, fast
* "gbm" (gradient boosting machine from the `gbm` R package)
  * ensemble method, typically tree-based, slow
* "gam" (generalized additive model from the `mgcv` package)
  * a combination of generalized linear model and additive models where the linear predictor is an additive function of the covariates, can be slow

The main example above used a Poisson regression but you can try the other 2 non-linear and more flexible options. Below, we use `cvcount()` as the example code but this can be applied to `pmcount()` as well. 

```{r initial_predictor_gbm_gam, eval = F, echo = T}
# An example of using GBM as the initial predictor method
cv(response = "count",
   cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses 
                                + offset(log(years)),
   ps.model = trt ~ age + previous_treatment, 
   data = countExample,
   higher.y = FALSE,
   score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
   initial.predictor.method = "gbm",       # NEW
   cv.n = 5, 
   plot.gbmperf = FALSE,
   seed = 999 #, n.cores = 2
   )

# An example of using GAM as the initial predictor method
cv(response = "count",
   cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses 
                                + offset(log(years)),
   ps.model = trt ~ age + previous_treatment, 
   data = countExample,
   higher.y = FALSE,
   score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
   initial.predictor.method = "gam",        # NEW
   xvar.smooth = c("age", "previous_cost"), # NEW
   cv.n = 5, 
   plot.gbmperf = FALSE,
   seed = 999 #, n.cores = 2
   )
```

Note that for the GAM method, there is an additional argument called `xvar.smooth`. If left as default (which is NULL), GAM will include all independent variables in `cate.model` as smooth terms with function `s()` in the linear predictor. You can choose to specify only a subset of the dependent variables as the smooth terms. In the example above, the specifications `cate.model` and `xvar.smooth` lead to the following GAM formula: `y ~ female + previous_treatment + previous_number_relapses + s(age) + s(previous_cost)`, where only age and previous medical costs are wrapped in the smooth function and the remaining 3 independent variables are not. 

Generally speaking, the "poisson" initial predictor method is the fastest and "gbm" is the slowest among the 3 methods, while "gam" is somewhere in between with longer computational time as the number of smooth terms increases.


## Subgroup proportion
The ATE by subgroups and validation curve results depend on how the subgroups are defined, which is determined by the sorted CATE scores. There could be nested binary subgroups (cutoffs specified by `prop.cutoff`) or mutually exclusive subgroups (cutoffs specified by `prop.multi`). In the main example above, we used the default values of `prop.cutoff` and `prop.multi` and we have provided explanations in the ATE results. Here is a recap:

* `prop.cutoff` = seq(0.5, 1, length = 6) means that we have 6 sets of nested binary subgroups where the first subgroup splits the sample by 50/50 according to the estimated CATE scores (sorted), the 2nd subgroup splits the sample by 60/40, ..., the 5th subgroup splits the sample by 90/10, and the 6th subgroup splits the sample by 100/0. The validation curves show the ATE in the first group of each split, i.e., 50%, 60%, 70%, ..., 100%. The 6th subgroup is technically not a split but we keep it because it is equivalent to the overall ATE (the gray dashed reference line). The functions that use `prop.cutoff` will automatically discard 0 if supplied because 0/100 split does not make sense as there is no 0% subgroup to plot for the validation curves, and a warning message will be given. The argument `higher.y` controls the direction of the sorted CATE scores, i.e., whether we split from the lowest or the highest CATE scores. For our toy example, `higher.y` = FALSE so we split from the lowest CATE scores such that the first group in each subgroup represents higher responders to the treatment coded with 1.

* `prop.multi` = c(0, 1/3, 2/3, 1) means that we specify a 3-category mutually exclusive subgroup, split by 33/33/33 according to the estimated CATE scores. The argument `higher.y` controls the direction of the sorted CATE scores, i.e., where we split from the lowest or the highest CATE scores. For our toy example, `higher.y` = FALSE so we split from the lowest CATE scores. Contrary to `prop.cutoff`, `prop.multi` must include both 0 and 1 to remind us of the mutual exclusiveness. he functions that use `prop.multi` will automatically attach 0 and/or 1 if they are not supplied and a warning message will be given. 

Now we show more examples of different cutoffs and how they are reflected in the results. 

```{r subgroup_proportion, eval = T, echo = T}
# An example of 11 nested binary subgroups and a 4-category mutually exclusive subgroup
output_cv2 <- cvcount(cate.model = y ~ age + female + previous_treatment 
                                      + previous_cost + previous_number_relapses 
                                      + offset(log(years)),
              ps.model = trt ~ age + previous_treatment, 
              data = countExample,
              higher.y = FALSE,
              score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
              prop.cutoff = seq(0.5, 1, length = 11), # NEW
              prop.multi = c(0, 1/4, 2/4, 3/4, 1),    # NEW
              initial.predictor.method = "poisson", 
              cv.n = 5, 
              plot.gbmperf = FALSE,
              seed = 999, 
              # n.cores = 2,
              verbose = FALSE)
```
```{r subgroup_proportion2, eval = T, echo = T}
print(output_cv2$ate.contrastReg$ate.est.train.high.cv) 
# Dimension is now 11 rows (nested binary subgroups) by 5 columns (CV iterations)
```

Because we have new `prop.cutoff` with 11 values as opposed to only 6 in the original example, the number of rows in the ATE results will be changed accordingly while the number of columns stays the same because we still use 5 CV iterations. 


```{r subgroup_proportion3, eval = T, echo = T}
plot(output_cv2) 
```

The validation curves depend on `prop.cutoff` and are now smoother than the one presented in the main example because they contain 10 subgroups instead of 5. The ABC statistic is not affected by the change in `prop.cutoff` because the calculation of ABC statistics depends on the minimum and maximum of the `prop.cutoff` vector and is always calculated based on 100 evenly-spaced cutoffs created from this range. See more theoretical details on ABC calculation in the [Theoretical details](#ABCdetails) section. 


```{r subgroup_proportion4, eval = T, echo = T}
print(output_cv2$ate.contrastReg$ate.est.train.group.cv) 
# Dimension is now 4 rows (multi-category mutually exclusive subgroups) by 5 columns (CV iterations)

boxplot(output_cv2)
```

For results on the mutually exclusive subgroups, the number of rows in the ATE results increases from 3 to 4 in comparison with the original example because `prop.multi` now defines 4 mutually exclusive subgroups. For each method, the box plot now has 4 boxes for 4 mutually exclusive subgroups.


**Examples that we do not recommend**

In this next example, `prop.cutoff` includes 0.01, which is very close to 0. Consequently, the scoring methods may run into some convergence issues because the first subgroup includes a small number of patients. This can lead to highly unstable ATE estimates, as shown in the first CV iteration of contrast regression in `output_cv3$ate.contrastReg$ate.est.valid.high.cv`. Moreover, the validation curves become useless due to the extreme ATE estimates.

```{r subgroup_proportion_bad, eval = T, echo = T}
# An example of very few nested binary subgroups
output_cv3 <- cv(response = "count",
                 cate.model = y ~ age + female + previous_treatment
                                      + previous_cost + previous_number_relapses 
                                      + offset(log(years)),
                 ps.model = trt ~ age + previous_treatment, 
                 data = countExample,
                 higher.y = FALSE,
                 score.method = c("poisson", "boosting", "twoReg", "contrastReg", "negBin"),
                 prop.cutoff = c(0, 0.01, 0.30, 0.75, 1), # NEW
                 initial.predictor.method = "poisson", 
                 cv.n = 5, 
                 plot.gbmperf = FALSE,
                 seed = 9, 
                 # n.cores = 2,
                 verbose = 0)

output_cv3$ate.contrastReg$ate.est.valid.high.cv
```

```{r subgroup_proportion_bad2, eval = T, echo = T, warning=FALSE, message=FALSE}
plot(output_cv3) 

```

Below are some general recommendations on the choice of `prop.cutoff` and `prop.multi`:

1. We do not recommend including 0 in `prop.cutoff` as it is an invalid value. The functions will automatically remove 0 in `prop.cutoff` and output a warning message.
2. We do not recommend choosing values too close to 0 either because this will generate very small subgroups which may lead to numerical instability, e.g., 1/99 split specified by 0.01 in this example and corresponding ATE in the training data for contrast regression. In this situation, either the validation curves will be dominated by the unstable ATE estimates, making the plot useless as in this example, or the validation curves will not be plotted if the numerical instability due to an extreme split leads to missing values, in which case a warning is printed as in the example above. 
3. In general, we do not recommend specifying too few proportions for `prop.cutoff` (e.g., 2 or 3) because the validation curves will look jagged. The validation curves will be smoother with more proportions spread out over the range of proportions. If computation is an issue, however, choosing too many values for `prop.cutoff` or `prop.multi` can be time consuming. It is recommended to start from a smaller length and you can increase the length as needed. 

# Function description {#fundescr}

## `cv()`{#cvcountdescr}

### Description {.unlisted .unnumbered}

Provides (doubly robust) estimation of the ATE for count or survival outcomes in nested and mutually exclusive subgroups of patients defined by an estimated CATE score via CV.

### Usage {.unlisted .unnumbered}

```{r cvcount, eval = F, echo = T}
cv(
  response, 
  cate.model, 
  ps.model, 
  data, 
  score.method,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  higher.y = TRUE, 
  abc = TRUE, 
  prop.cutoff = seq(0.5, 1, length = 6), 
  prop.multi = c(0, 1/3, 2/3, 1),
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99,
  train.prop = 3/4, 
  cv.n = 10, 
  error.max = 0.1, 
  max.iter = 5000,
  initial.predictor.method = NULL, 
  xvar.smooth = NULL,
  tree.depth = 2, 
  n.trees.rf = 1000, 
  n.trees.boosting = 200, 
  B = 3, 
  Kfold = 5,
  error.maxNR = 1e-3, 
  max.iterNR = 150, 
  tune = c(0.5, 2),
  seed = NULL, 
  plot.gbmperf = TRUE, 
  verbose = 2
  )
```

### Arguments {.unlisted .unnumbered}

Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `cvcount()`) and "survival" (see `cvsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`score.method`          A vector of one or multiple methods to estimate the CATE score. Allowed values are: "boosting", "poisson", "twoReg", "contrastReg", "negBin" (count outcomes only), and "randomForest" (survival outcomes only).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`higher.y`              A logical value indicating whether higher (TRUE) or lower (FALSE) values of the outcome are more desirable. Default is TRUE.
`abc`                   A logical value indicating whether the ABC should be calculated at each CV iterations, for each `score.method`. Default is TRUE.
`prop.cutoff`           A vector of numerical values (in (0, 1]) specifying percentiles of the estimated log CATE scores to define nested subgroups. Each element represents the cutoff to separate observations in nested subgroups (below vs above cutoff). The length of `prop.cutoff` is the number of nested subgroups. An equally-spaced sequence of proportions ending with 1 is recommended. Default is `seq(0.5, 1, length = 6)`.
`prop.multi`            A vector of numerical values (in [0, 1]) specifying percentiles of the estimated log CATE scores to define mutually exclusive subgroups. It should start with 0, end with 1, and be of `length(prop.multi) > 2`. Each element represents the cutoff to separate the observations into `length(prop.multi) - 1` mutually exclusive subgroups. Default is `c(0, 1/3, 2/3, 1)`.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.
`train.prop`            A numerical value (in (0, 1)) indicating the proportion of total data used for training. Default is 3/4.
`cv.n`                  A positive integer value indicating the number of CV iterations. Default is 10.


Additional arguments            Description
---------------------           ------------
`ipcw.method`           A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`error.max`                     A numerical value > 0 indicating the tolerance (maximum value of error) for the largest standardized absolute difference in the covariate distributions or in the doubly robust estimated rate ratios between the training and validation sets. This is used to define a balanced training-validation splitting. Default is 0.1.
`max.iter`                      A positive integer value indicating the maximum number of iterations when searching for a balanced training-validation split. Default is 5,000.
`initial.predictor.method`      A character vector for the method used to get initial outcome predictions conditional on the covariates specified in `cate.model`. Only applies when `score.method` includes "twoReg" or "contrastReg". Allowed values include one of "randomForest" (survival outcomes only), "boosting", "logistic" (survival outcomes only, fast), "poisson" (count outcomes only, fast), and "gam" (count outcomes only). Default is NULL, which assigns "boosting" for count outcomes and "randomForest" for survival outcomes.
`xvar.smooth`                   A vector of characters indicating the name of the variables used as the smooth terms if `initial.predictor.method` = "gam". The variables must be selected from the variables listed in `cate.model`. Only applies for count outcomes. Default is NULL, which uses all variables in `cate.model`.
`tree.depth`                    A positive integer specifying the depth of individual trees in boosting (usually 2-3). Used only if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 2.
`n.trees.rf`                    A positive integer specifying the maximum number of trees in random forest. Used if `score.method` = "ranfomForest" or if `initial.predictor.method` = "randomForest" with `score.method` = "twoReg" or "contrastReg". Only applies for survival outcomes. Default is 1000.
`n.trees.boosting`              A positive integer specifying the maximum number of trees in boosting (usually 100-1000). Used if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 200.
`B`                             A positive integer specifying the number of time cross-fitting is repeated in `score.method` = "twoReg" and "contrastReg". Default is 3.
`Kfold`                         A positive integer specifying the number of folds used in cross-fitting to partition the data in `score.method` = "twoReg" and "contrastReg". Default is 5.
`error.maxNR`                   A numerical value > 0 indicating the minimum value of the mean absolute error in Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 0.001.
`max.iterNR`                    A positive integer indicating the maximum number of iterations in the Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 150.
`tune`                          A vector of 2 numerical values > 0 specifying tuning parameters for the Newton Raphson algorithm. `tune[1]` is the step size, `tune[2]` specifies a quantity to be added to diagonal of the slope matrix to prevent singularity. Used only if `score.method` = "contrastReg". Default is `c(0.5, 2)`.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`plot.gbmperf`                  A logical value indicating whether to plot the performance measures in boosting. Used only if `score.method` = "boosting" or if `score.method` = "twoReg" or "contrastReg" and `initial.predictor.method` = "boosting". Default is TRUE.
`verbose`                       An integer value indicating what kind of intermediate progress messages should be printed. `0` means no outputs. `1` means only progress bar and run time. `2` means progress bar, run time, and all errors and warnings. Default is 2.


### Value {.unlisted .unnumbered}

For count outcomes, the function returns a list containing the following components saved as a "PrecMed" object:

* **ate.poisson**: A list of results output if `score.method` includes "poisson":

    * **ate.est.train.high.cv**: A matrix of numerical values with `length(prop.cutoff)` rows and `cv.n` columns. The ith row/jth column cell contains the estimated ATE in the nested subgroup of high responders defined by CATE score above (if `higher.y` = TRUE) or below (if `higher.y` = FALSE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **ate.est.train.low.cv**: A matrix of numerical values with `length(prop.cutoff) - 1` rows and `cv.n` columns. The ith row/jth column cell contains the estimated ATE in the nested subgroup of low responders defined by CATE score below (if `higher.y` = TRUE) or above (if `higher.y` = FALSE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **ate.est.valid.high.cv**: Same as `ate.est.train.high.cv`, but in the validation set.
    
    * **ate.est.valid.low.cv**: Same as `ate.est.train.low.cv`, but in the validation set.
    
    * **ate.est.train.group.cv**: A matrix of numerical values with `length(prop.multi) - 1` rows and `cv.n` columns. The jth column contains the estimated ATE in `length(prop.multi) - 1` mutually exclusive subgroups defined by `prop.multi` in the training set in jth CV iteration.
    
    * **ate.est.valid.group.cv**: Same as `ate.est.train.group.cv`, but in the validation set.
    
    * **abc.valid**: A vector of numerical values of length `cv.n`. The ith element returns the ABC of the validation curve in the ith CV iteration. Only returned if `abc` = TRUE.
    
* **ate.boosting**: A list of results similar to `ate.poisson` output if `score.method` includes "boosting".

* **ate.twoReg**: A list of results similar to `ate.poisson` output if `score.method` includes "twoReg".

* **ate.contrastReg**: A list of results similar to `ate.poisson` output if `score.method` includes "contrastReg". This method has an additional element in the list of results:

    * **converge.contrastReg.cv**: A vector of logical value of length `cv.n`. The ith element indicates whether the algorithm converged in 

* **ate.negBin**: A list of results similar to `ate.poisson` output `score.method` includes "negBin".

* **props**: A list of 3 elements:

    * **prop.onlyhigh**: The original argument `prop.cutoff`, reformatted as necessary.
    
    * **prop.bi**: The original argument `prop.cutoff`, similar to `prop.onlyhigh` but reformatted to exclude 1.
    
    * **prop.multi**: The original argument `prop.multi`, reformatted as necessary to include 0 and 1.

* **overall.ate.valid**: A vector of numerical values of length `cv.n`. The ith element contains the ATE in the validation set of the ith CV iteration, estimated with the doubly robust estimator.

* **overall.ate.train**: A vector of numerical values of length `cv.n`. The ith element contains the ATE in the training set of the ith CV iteration, estimated with the doubly robust estimator.

* **fgam**: The formula used in GAM if `initial.predictor.method` = "gam".

* **higher.y**: The original `higher.y` argument.

* **abc**: The original `abc` argument.

* **cv.n**: The original `cv.n` argument.

* **response**: The type of response. Always "count" for this function.

* **formulas**: A list of 3 elements: (1) `cate.model` argument, (2) `ps.model` argument and (3) original labels of the left-hand side variable in `ps.model` (treatment) if it was not 0/1.



### Details {.unlisted .unnumbered}

The CATE score represents an individual-level treatment effect expressed as a rate ratio for count outcomes. It can be estimated with boosting, Poisson regression, negative binomial regression, and the doubly robust estimator two regressions (@yadlowsky2020estimation) applied separately by treatment group or with the other doubly robust estimator contrast regression (@yadlowsky2020estimation) applied to the entire data set.

Internal CV is applied to reduce optimism in choosing the CATE estimation method that captures the most treatment effect heterogeneity. The CV is applied by repeating the following steps `cv.n` times:

1. Split the data into a training and validation set according to `train.prop`. The training and validation sets must be balanced with respect to covariate distributions and doubly robust rate ratio estimates (see `error.max`).

2. Estimate the CATE score in the training set with the specified scoring method.

3. Predict the CATE score in the validation set using the scoring model fitted from the training set.

4. Build nested subgroups of treatment responders in the training and validation sets, separately, and estimate the ATE within each nested subgroup. For each element i of `prop.cutoff` (e.g., `prop.cutoff[i]` = 0.6), take the following steps:

    4.1. Identify high responders as observations with the 60% (i.e., `prop.cutoff[i]`x100%) highest (if `higher.y` = TRUE) or lowest (if `higher.y` = FALSE) estimated CATE scores.
    
    4.2. Estimate the ATE in the subgroup of high responders using a doubly robust estimator.
    
    4.3. Conversely, identify low responders as observations with the 40% (i.e., 1 - `prop.cutoff[i]`x100%) lowest (if `higher.y` = TRUE) or highest (if `higher.y` = FALSE) estimated CATE scores.
    
    4.4. Estimate the ATE in the subgroup of low responders using a doubly robust estimator.

5. If `abc` = TRUE, calculate the area between the ATE and the series of ATEs in nested subgroups of high responders in the validation set.

6. Build mutually exclusive subgroups of treatment responders in the training and validation sets, separately, and estimate the ATE within each subgroup. Mutually exclusive subgroups are built by splitting the estimated CATE scores according to `prop.multi`.

## `abc()`

### Description {.unlisted .unnumbered}
Compute the area between curves (ABC) for each scoring method in the \code{"PrecMed"} object. This should be run only after results of \code{cv()} have been obtained.

### Usage {.unlisted .unnumbered}

```{r abc, eval = F, echo = T}
abc(x)
```

### Arguments {.unlisted .unnumbered}

Main argument   Description
--------------  ------------
`x`             An object of class "PrecMed".

### Value {.unlisted .unnumbered}
Returns a matrix of numeric values with number of columns equal to the number of cross-validation iterations and number of rows equal to the number of scoring methods in `x`. 

### Details {.unlisted .unnumbered}
The ABC is the area between a validation curve and the overall ATE in the validation set. It is calculated for each scoring method separately. Higher ABC values are preferable as they indicate that more treatment effect heterogeneity is captured by the scoring method. Negative values of ABC are possible if segments of the validation curve cross the overall ATE line. The ABC is calculated with `auc()` in the `MESS` package with a natural cubic spline interpolation. The calculation of the ABC is always based on validation curves based on 100 proportions equally spaced from `min(prop.cutoff)` to `max(prop.cutoff)`.

The ABC is a metric to help users select the best scoring method in terms of capturing treatment effect heterogeneity in the data. It should be used in complement to the visual inspection of the validation curves in the validation set in `plot()`. See @zhao2013effectively.

## `plot()`{#plotdescr}

### Description {.unlisted .unnumbered}

Provides validation curves in two side-by-side plots, visualizing the estimated ATEs in a series of nested subgroups in the training set and validation set separately, where each line represents one scoring method specified in `cv()`. This should be run only after results of `cv()` have been obtained.

### Usage {.unlisted .unnumbered}

```{r plot, eval = F, echo = T}
plot(
  x,
  cv.i = NULL,
  combine = "mean",
  show.abc = TRUE,
  valid.only = FALSE,
  plot.hr = FALSE,
  ylab = NULL,
  legend.position = "bottom",
  grayscale = FALSE,
  xlim = NULL
  )
```

### Arguments {.unlisted .unnumbered}
Main argument         Description
--------------        ------------
`x`                   An object of class "PrecMed".

Additional arguments      Description
---------------------     ------------
`cv.i`                    A positive integer indicating the index of the CV iteration results to be plotted. Allowed values are: a positive integer $<=$ `cv.n` in `cv()` or NULL. If `cv.i` = NULL, the results across all CV iterations are combined according to `combine` and then plotted. Default is NULL.
`combine`                 A character value indicating how to combine the estimated ATEs across all CV iterations into a validation curve for each nested subgroup, separately for the training and validation results. Allowed values are: "mean" or "median". Used only if `cv.i` = NULL. Default is "mean".
`show.abc`                A logical value indicating whether to show the ABC statistics in the validation set. Used only if `x$abc` = TRUE and `xlim` is not limited to a smaller range (i.e., `xlim` = NULL or equal to the entire `x$prop.onlyhigh` range). If `cv.i` is NULL, ABC statistics will be based on the combined CV iterations. If `cv.i` is an integer, ABC statistics will be based solely on that CV iteration. Default is TRUE.
`valid.only`              A logical value indicating whether only the validation curves in the validation set should be plotted (TRUE). Otherwise, the validation curves in both the training and validation sets are plotted side-by-side (FALSE). Default is FALSE.
`plot.hr`                 A logical value indicating whether the hazard ratios should be plotted in the validation curves (TRUE). Otherwise, the restricted mean time lost is plotted (FALSE). This argument is only applicable to survival outcomes. Default is FALSE.
`ylab`                    A character value for the y-axis label to describe what the ATE is. Default is NULL, which creates a default y-axis label based on available data. 
`legend.position`         A character value for the legend position argument to be passed to `ggplot` object. Default is "bottom".
`grayscale`               A logical value indicating grayscale plots (TRUE) or colored plots (FALSE). Default is FALSE.
`xlim`                    A numeric value for the range of the x-axis. Default is NULL, which means there is no range specified.

### Value {.unlisted .unnumbered}
Returns two side-by-side line plots, one of which shows the validation curves of the training sets and the other the validation curves in the validation sets. A gray horizontal dashed line of overall ATE is included as a reference. ABC statistics will be added to the legend if `show.abc` = TRUE.

### Details {.unlisted .unnumbered}

`plot()` takes in outputs from `cv()` and generates two plots of validation curves side-by-side, one for the training set and one for validation set. Separate validation curves are produced for each scoring method specified `via score.method` in `cv()`.

The validation curves (and ABC statistics, if applicable) can help compare the performance of different scoring methods in terms of discerning potential treatment heterogeneity in subgroups with internal validation. Steeper validation curves in the validation set suggest presence of treatment effect heterogeneity (and the ability of the scoring methods to capture it) while flat validation curves indicate absence of treatment effect heterogeneity (or inability of the scoring method to capture it).

## `boxplot()`

### Description {.unlisted .unnumbered}

Provides box plots which depict distributions of estimated ATEs for each multi-category subgroup in the validation set across all cross-validation iterations. The subgroups are mutually exclusive and are categorized by the CATE score percentiles (`prop.multi` specified in `cv()`). Box plots of mutually exclusive subgroups are constructed separately by scoring method specified in `cv()`. This should be run only after results of `cv()` have been obtained.

### Usage {.unlisted .unnumbered}

```{r boxplot, eval = F, echo = T}
boxplot(
  x,
  ylab = NULL,
  plot.hr = FALSE,
  grayscale = FALSE
  )
```

### Arguments {.unlisted .unnumbered}

Main argument       Description
--------------      ------------
`x`                 An object of class "PrecMed".

Additional argument       Description
--------------------      ------------
`ylab`                    A character value for the y-axis label to describe what the ATE is. Default is NULL, which creates a default y-axis label based on available data. 
`plot.hr`                 A logical value indicating whether the hazard ratios should be plotted in the validation curves (TRUE). Otherwise, the restricted mean time lost is plotted (FALSE). This argument is only applicable to survival outcomes. Default is FALSE.
`grayscale`               A logical value indicating grayscale plots (TRUE) or colored plots (FALSE). Default is FALSE.

### Value {.unlisted .unnumbered}
Returns sets of box plots, one set for each scoring method, over each of the multi-category subgroups. A gray horizontal dashed line of the overall ATE is included as a reference.

### Details {.unlisted .unnumbered}
`boxplot()` takes in outputs from `cv()` and generates the box plots of estimated ATEs for multi-category subgroups of the validation set. The box plots together with the overall ATE reference line can help compare the scoring methods' ability to distinguish subgroups of patients with different treatment effects.

For a given scoring method, box plots showing increasing or decreasing trends across the multi-category subgroups indicate presence of treatment effect heterogeneity (and the ability of the scoring method to capture it). On the contrary, box plots which are relatively aligned across the multi-category subgroups indicate absence of treatment effect heterogeneity (or the inability of the scoring method to capture it).

## `pm()` {#pmcountdescr}

### Description {.unlisted .unnumbered}

Provides singly robust and doubly robust estimation of CATE score for count and survival data with the following scoring methods: Random forest (survival only), boosting, poisson regression, two regressions, contrast regression, and negative binomial regression (count only).

### Usage {.unlisted .unnumbered}

```{r pmcount, eval = F, echo = T}
pm(
  response, 
  cate.model, 
  ps.model, 
  data, 
  score.method,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  higher.y = TRUE, 
  prop.cutoff = seq(0.5, 1, length = 6), 
  prop.multi = c(0, 1/3, 2/3, 1),
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99,
  initial.predictor.method = NULL, 
  xvar.smooth = NULL,
  tree.depth = 2, 
  n.trees.rf = 1000, 
  n.trees.boosting = 200, 
  B = 3, 
  Kfold = 5,
  error.maxNR = 1e-3, 
  max.iterNR = 150, 
  tune = c(0.5, 2),
  seed = NULL, 
  plot.gbmperf = TRUE
  )
```


### Arguments {.unlisted .unnumbered}


Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `pmcount()`) and "survival" (see `pmsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`score.method`          A vector of one or multiple methods to estimate the CATE score. Allowed values are: "boosting", "poisson", "twoReg", "contrastReg", "negBin" (count outcomes only), and "randomForest" (survival outcomes only).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`higher.y`              A logical value indicating whether higher (TRUE) or lower (FALSE) values of the outcome are more desirable. Default is TRUE.
`prop.cutoff`           A vector of numerical values (in (0, 1]) specifying percentiles of the estimated log CATE scores to define nested subgroups. Each element represents the cutoff to separate observations in nested subgroups (below vs above cutoff). The length of `prop.cutoff` is the number of nested subgroups. An equally-spaced sequence of proportions ending with 1 is recommended. Default is `seq(0.5, 1, length = 6)`.
`prop.multi`            A vector of numerical values (in [0, 1]) specifying percentiles of the estimated log CATE scores to define mutually exclusive subgroups. It should start with 0, end with 1, and be of `length(prop.multi) > 2`. Each element represents the cutoff to separate the observations into `length(prop.multi) - 1` mutually exclusive subgroups. Default is `c(0, 1/3, 2/3, 1)`.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.

Additional arguments            Description
------------------------        ------------------
`ipcw.method`                   A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`initial.predictor.method`      A character vector for the method used to get initial outcome predictions conditional on the covariates specified in `cate.model`. Only applies when `score.method` includes "twoReg" or "contrastReg". Allowed values include one of "randomForest" (survival outcomes only), "boosting", "logistic" (survival outcomes only, fast), "poisson" (count outcomes only, fast), and "gam" (count outcomes only). Default is NULL, which assigns "boosting" for count outcomes and "randomForest" for survival outcomes.
`xvar.smooth`                   A vector of characters indicating the name of the variables used as the smooth terms if `initial.predictor.method` = "gam". The variables must be selected from the variables listed in `cate.model`. Only applies for count outcomes. Default is NULL, which uses all variables in `cate.model`.
`tree.depth`                    A positive integer specifying the depth of individual trees in boosting (usually 2-3). Used only if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 2.
`n.trees.rf`                    A positive integer specifying the maximum number of trees in random forest. Used if `score.method` = "ranfomForest" or if `initial.predictor.method` = "randomForest" with `score.method` = "twoReg" or "contrastReg". Only applies for survival outcomes. Default is 1000.
`n.trees.boosting`              A positive integer specifying the maximum number of trees in boosting (usually 100-1000). Used if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 200.
`B`                             A positive integer specifying the number of time cross-fitting is repeated in `score.method` = "twoReg" and "contrastReg". Default is 3.
`Kfold`                         A positive integer specifying the number of folds used in cross-fitting to partition the data in `score.method` = "twoReg" and "contrastReg". Default is 5.
`error.maxNR`                   A numerical value > 0 indicating the minimum value of the mean absolute error in Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 0.001.
`max.iterNR`                    A positive integer indicating the maximum number of iterations in the Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 150.
`tune`                          A vector of 2 numerical values > 0 specifying tuning parameters for the Newton Raphson algorithm. `tune[1]` is the step size, `tune[2]` specifies a quantity to be added to diagonal of the slope matrix to prevent singularity. Used only if `score.method` = "contrastReg". Default is `c(0.5, 2)`.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`plot.gbmperf`                  A logical value indicating whether to plot the performance measures in boosting. Used only if `score.method` = "boosting" or if `score.method` = "twoReg" or "contrastReg" and `initial.predictor.method` = "boosting". Default is TRUE.


### Value {.unlisted .unnumbered}

Returns a list containing the following components:

* **ate.poisson**: A vector of numerical values of length `prop.cutoff` containing the estimated ATE in nested subgroups (defined by `prop.cutoff`) constructed based on the estimated CATE score with poisson regression. Only provided if `score.method` includes "poisson".

* **ate.boosting**: Same as `$ate.poisson`, but with the nested subgroups based the estimated CATE score with boosting. Only provided if `score.method` includes "boosting".

* **ate.twoReg**: Same as `$ate.poisson`, but with the nested subgroups based the estimated CATE score with two regressions. Only provided if `score.method` includes "twoReg".

* **ate.contrastReg**: Same as `$ate.poisson`, but with the nested subgroups based the estimated CATE score with contrast regression. Only provided if `score.method` includes "contrastReg".

* **ate.negBin**: Same as `$ate.poisson`, but with the nested subgroups based the estimated CATE score with negative binomial regression. Only provided if `score.method` includes "negBin".

* **score.poisson**: A vector of numerical values of length n (number of observations in `data`) containing the estimated log-CATE score according to the Poisson regression. Only provided if `score.method` includes "poisson".

* **score.boosting**: Same as `$score.poisson`, but with estimated log-CATE score according to boosting. Only provided if `score.method` includes "boosting".

* **score.twoReg**: Same as `$score.poisson`, but with estimated log-CATE score according to two regressions. Only provided if `score.method` includes "twoReg".

* **score.contrastReg**: Same as `$score.poisson`, but with estimated log-CATE score according to contrast regression. Only provided if `score.method` includes "contrastReg".

* **score.negBin**: Same as `$score.poisson`, but with estimated log-CATE score according to negative binomial regression. Only provided if `score.method` includes "negBin".

* **fit**: Additional details on model fitting if `score.method` includes "boosting" or "contrastReg":

    * **result.boosting**: Details on the boosting model fitted to observations with treatment = 0 (\$fit0.gbm) and to observations with treatment = 1 (\$fit1.gbm). Only provided if `score.method` includes "boosting".
    
    * **result.contrastReg$sigma.contrastReg**: Variance-covariance matrix of the estimated log-CATE coefficients in contrast regression. Only provided if `score.method` includes "contrastReg".

* **coefficients**: A data frame with the coefficients of the estimated log-CATE score by `score.method`. The data frame has number of rows equal to the number of covariates in `cate.model` and number of columns equal to length(`score.method`). If `score.method` includes "contrastReg", the data frame has an additional column containing the standard errors of the coefficients estimated with contrast regression. "boosting" does not have coefficient results because tree-based methods typically do not express the log-CATE as a linear combination of coefficients and covariates.

### Details {.unlisted .unnumbered}

The CATE score represents an individual-level treatment effect, estimated with either Poisson regression, boosting or negative binomial regression applied separately by treatment group or with two doubly robust estimators, two regressions and contrast regression (@yadlowsky2020estimation), applied in the entire data set.

`pm()` provides the coefficients of the CATE score for each scoring method requested through `score.method`. Currently, contrast regression is the only method which allows for inference of the CATE coefficients by providing standard errors of the coefficients. The coefficients can be used to learn the effect size of each variable and predict the CATE score for a new observation.

`pm()` also provides predictions of the CATE score for each observation in the data set, for each scoring method. The predictions allow ranking the observations from high potential responders to the treatment to low or standard responders.

The estimated ATE among nested subgroups of high responders are also provided by scoring method. Note that the ATEs in `pm()` are derived based on the CATE score which is estimated using the entire data sample. Therefore, overfitting may be an issue. `cv()` is more suitable to inspect the estimated ATEs across scoring methods as it implements internal CV to reduce optimism.

## `dr.inference()`

### Description {.unlisted .unnumbered}

Doubly robust estimator of the average treatment effect between two treatments, which is the rate ratio for count outcomes and the restricted mean time lost ratio for survival outcomes. Bootstrap is used for inference.

### Usage {.unlisted .unnumbered}

```{r drinf, eval = F, echo = T}
dr.inference(
  response, 
  cate.model, 
  ps.model, 
  data,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99, 
  interactions = TRUE,
  n.boot = 500, 
  seed = NULL, 
  verbose = 1, 
  plot.boot = FALSE
  )
```

### Arguments {.unlisted .unnumbered}

Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `pmcount()`) and "survival" (see `pmsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.

Additional arguments            Description
------------------------        ------------------
`ipcw.method`                   A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`interactions`                  A logical value indicating whether the outcome model should assume interactions x and trt. Applies only to count outcomes. If TRUE, interactions will be assumed only if at least 10 patients received each treatment option. Default is TRUE.
`n.boot`                        A numeric value indicating the number of bootstrap samples used. Default is 500.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`verbose`                       An integer value indicating whether intermediate progress messages and histograms should be printed. `1` indicates messages are printed and `0` otherwise. Default is `1`.
`plot.boot`                     A logical value indicating whether histograms of the bootstrapped log(rate ratio) (for count outcomes) log(restricted mean time lost ratio) (for survival outcomes) should be produced at every `n.boot`/10-th iteration and whether the final histogram should be outputted. This argument is only taken into account if `verbose` = 1. Default is FALSE.


### Value {.unlisted .unnumbered}

Return a list of 5 elements:

* **log.rate.ratio**: A vector of numeric values of the estimated log rate ratio of trt=1 over trt=0, bootstrap standard error, lower and upper limits of 95% confidence interval, and the p-value.

* **rate0**: A numeric value of the estimated rate in the group trt=0.

* **rate1**: A numeric value of the estimated rate in the group trt=1.

* **warning**: A warning message produced if the treatment variable was not coded as 0/1. The key to map the original coding of the variable to a 0/1 key is displayed in the warning to facilitate the interpretation of the remaining of the output.

* **plot**: If `plot.boot` is TRUE, a histogram displaying the distribution of the bootstrapped log rate ratios. The red vertical reference line in the histogram represents the estimated log rate ratio.

### Details {.unlisted .unnumbered}

This helper function estimates the average treatment effect (ATE) between two treatment groups in a given dataset. The ATE is estimated with a doubly robust estimator that accounts for imbalances in covariate distributions between the two treatment groups with inverse probability treatment weighting. 

For count outcomes, the estimated ATE is the estimated rate ratio between treatment 1 versus treatment 0. The log-transformed ATEs are returned, as well as the rate in either treatment group. The variability of the estimated rate ratio is also calculated using bootstrap. Additional outputs include standard error of the log rate ratio, 95% confidence interval, p-value, and a histogram of the bootstrap estimates.

# Theoretical details {#theodetail}

Assume that the following data are recorded for each of $n$ observations:

* $R$ is a binary treatment taking value 0 or 1. 
* $\boldsymbol{X}$ is a vector of $p$ baseline covariates.
* $Y$ is a count outcome.
* $T$ is the exposure time during which $Y$ is recorded. It can vary across observations.

The objective is to estimate the ratio-based CATE score defined as 

$$CATE(\boldsymbol{x})=\text{log}\left(\frac{\mathbb{E}[Y^{(1)}|\boldsymbol{X}=\boldsymbol{x},T=1]}{\mathbb{E}[Y^{(0)}|\boldsymbol{X}=\boldsymbol{x},T=1]}\right)$$
where $Y^{(r)}$ is the potential outcome if the patient received the treatment $r \in \{0,1\}$. $CATE(\boldsymbol{x})$ is interpreted as the individualized log-rate ratio of treatment 1 over treatment 0 conditional on the baseline covariates. 

The package offers 5 methods to estimate the CATE score: Poisson regression, negative binomial regression, boosting, two regressions, and contrast regression.

## Poisson

1. Estimate the conditional mean outcome given baseline covariates and log-transformed exposure time as the offset separately in each treatment group (i.e., $\text{log}(\mathbb{E}[Y^{(r)}|\boldsymbol{x},t])=\beta_r \boldsymbol{\tilde x}$ for $r \in \{0,1\}$ where $\boldsymbol{\tilde x}$ is the $x$ with an intercept) with Poisson regression. Denote the prediction for one time unit as $\hat Y^{(r)}(\boldsymbol{x},1)=\text{exp}(\hat \beta_r \boldsymbol{\tilde x})$.

2. The CATE score with Poisson is the plug-in estimator

$$\hat{CATE}_{Poisson}(\boldsymbol{x})=\text{log}\left(\frac{\hat Y^{(1)}(\boldsymbol{x},1)}{\hat Y^{(0)}(\boldsymbol{x},1)}\right)$$

## Negative binomial

Follow the same step as in Poisson but replace Poisson regression with negative binomial regression in step 1. 

## Boosting

1. Estimate the conditional mean outcome given baseline covariates and log-transformed exposure time as the offset separately in each treatment group (i.e., $\mathbb{E}[Y^{(r)}|\boldsymbol{x},t]$ for $r \in \{0,1\}$) with Poisson-based gradient boosting regression method. Denote the prediction for one time unit as $\hat Y^{(r)}(\boldsymbol{x},1)$.

    * The base learners are regression trees with depth specified with the argument `tree.depth` in `cvcount()` and `pmcount()`. Default is 2.
    * The number of trees in boosting is selected via cross-validation with a maximum number of trees specificed with the argument `n.trees` in `cvcount()` and `pmcount()`. Default is 200.
    
2. 	The CATE score with boosting is the plug-in estimator

$$\hat{CATE}_{boosting}(\boldsymbol{x})=\text{log}\left(\frac{\hat Y^{(1)}(\boldsymbol{x},1)}{\hat Y^{(0)}(\boldsymbol{x},1)}\right)$$

## Two regressions

1. Randomly separate the data $D$ into $K$ (`Kfold`) non-overlapping parts of approximately equal sizes, $D_1, \dots, D_K$.
2. For each fold $k=1,\dots,K$, and separately by treatment group $r \in \{0,1\}$:

    2.1 Estimate the conditional mean outcome given baseline covariates and log-transformed exposure time as the offset with the
    Poisson-based gradient boosting regression method based on observations without the kth fold, $D_{-k}$, and denote the prediction as $\hat Y_{-k}^{(r)}(\boldsymbol{x},t)$. This is the initial nonparametric prediction of the potential outcome.
    
    2.2 Estimate the PS based on $D_{-k}$. Denote the estimated PS as $\hat \pi_{-k}(\boldsymbol{x})$ and estimate the weights $\hat W(r)=r\frac{R}{\hat \pi_{-k}(\boldsymbol{x})}+(1-r)\frac{(1-R)}{1-\hat \pi_{-k}(\boldsymbol{x})}$ with $R$ denoting the treatment received.
    
    2.3 Solve the following weighted estimating equation by fitting a Poisson regression with $Y$ as the response, $\text{log}(\hat Y^{(r)}(\boldsymbol{x},1))$ and $x$ as the covariates, $\text{log}(T)$ as the offset, and $\hat W(r)$ as weight:
    
    $$S(\alpha_{rk}, \boldsymbol{\gamma_{rk}})=\sum_{i \in D_{-k}} \hat W(r) \pmatrix{\text{log}\left(\hat Y^{(r)}(\boldsymbol{x},1)\right)\\\boldsymbol{\tilde x}}\left(Y - \text{exp}\left(\alpha_{rk}\text{log}\left(\hat Y^{(r)}(\boldsymbol{x},1)\right)+\boldsymbol{\gamma_{rk}^T\boldsymbol{\tilde x}}\right)\times T\right)=0$$
    
    where $i$ denotes individual observations. Denote the roots by $(\hat \alpha_{rk}, \boldsymbol{\hat\gamma_{rk}})$.
    
3. Solve the following doubly robust estimating equation by fitting a Poisson regression with $\text{exp}\left(\hat\alpha_{rk}\text{log}\left(\hat Y^{(r)}(\boldsymbol{x},1)\right)+\boldsymbol{\hat\gamma_{rk}^T\boldsymbol{\tilde x}}\right)$ as the response, $\boldsymbol{x}$ as the covariates, and no offset or weight:
$$S(\boldsymbol{\beta_r})=\sum_{k=1}^K \sum_{i \in D_{-k}}\boldsymbol{\tilde x}\left(\text{exp}\left(\hat\alpha_{rk}\text{log}\left(\hat Y^{(r)}(\boldsymbol{x},1)\right)+\boldsymbol{\hat\gamma_{rk}^T\boldsymbol{\tilde x}}\right)-\text{exp}(\boldsymbol{\beta_r^T\tilde x})\right)=0$$
Denote the estimator as $\boldsymbol{\hat \beta_r}$. 

4. Repeat steps 1-3 with $B$ bootstrap samples and denote the estimator $\boldsymbol{\hat \beta_{rb}}$ in the $b$ sample. The final estimator $\boldsymbol{\hat \beta_r}$ is the mean of the $\boldsymbol{\hat \beta_{rb}}$.

5. The CATE score with two regressions is  

$$\hat{CATE}_{tworeg}(\boldsymbol{x})=(\boldsymbol{\hat \beta_1} - \boldsymbol{\hat \beta_0})^T\boldsymbol{\tilde x}$$

## Contrast regression

1. Randomly separate the data $D$ into $K$ (`Kfold`) non-overlapping parts of approximately equal sizes, $D_1, \dots, D_K$.
2. For each fold $k=1,\dots,K$, and separately by treatment group $r \in \{0,1\}$:

    2.1 Estimate the conditional mean outcome given baseline covariates and log-transformed exposure time as the offset with the
    Poisson-based gradient boosting regression method based on observations without the kth fold, $D_{-k}$, and denote the prediction as $\hat Y_{-k}^{(r)}(\boldsymbol{x},t)$. This is the initial nonparametric prediction of the potential outcome.
    
    2.2 Estimate the PS based on $D_{-k}$. Denote the estimated PS as $\hat \pi_{-k}(\boldsymbol{x})$.
    
3. Solve the following doubly robust estimating equation by Newton-Raphson method or using a L2-norm score method if the former fails to converge:
$$\begin{aligned}
S(\boldsymbol{\delta})&=\sum_{k=1}^K \sum_{i \in D_{-k}} \boldsymbol{\tilde x}\Bigg[\frac{R\left\{\frac{Y}{T}-\frac{1}{2}\left(\hat Y_{-k}^{(0)}(\boldsymbol{ x})\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x}) + \hat Y_{-k}^{(1)}(\boldsymbol{x})\right)\right\}(1-\hat\pi_{-k}(\boldsymbol{x}))}{\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})+1-\hat\pi_{-k}(\boldsymbol{x})}\\
&+\frac{(1-R)\left\{\frac{Y}{T}-\frac{1}{2}\left(\hat Y_{-k}^{(0)}(\boldsymbol{ x}) + \hat Y_{-k}^{(1)}(\boldsymbol{x})\text{exp}(-\boldsymbol{\delta^T}\boldsymbol{\tilde x})\right)\right\}\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})}{\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})+1-\hat\pi_{-k}(\boldsymbol{x})}\Bigg]=0
\end{aligned}$$
Denote the estimator as $\boldsymbol{\hat\delta}$.

4. Repeat steps 1-3 with $B$ bootstrap samples and denote the estimator $\boldsymbol{\hat \delta_b}$ in the $b$ sample. The final estimator $\boldsymbol{\hat \delta}$ is the mean of the $\boldsymbol{\hat \delta_b}$.

5. The CATE score with contrast regression is  

$$\hat{CATE}_{contrastreg}(\boldsymbol{x})=\boldsymbol{\hat \delta^T\tilde x}$$

## Validation curves and the ABC statistics {#ABCdetails}
The ABC statistic represents the area between the validation curve and the ATE. For a single CV iteration, it is implemented in the training and validation sets separately as following:

**Step 1**. Calculate the ATE in the training or validation sets.

**Step 2**. Calculate the ATE in 100 nested subgroups based on the estimated CATE score and derive the corresponding validation curve. Subgroups are defined with 100 equally-spaced proportions from `min(prop.cutoff)` to `max(prop.cutoff)` to ensure that enough data points are available to build the validation curve.

**Step 3**. The ABC is calculated with `auc()` from the MESS R package using the natural cubic spline interpolation, which calculates the area between the horizontal line with y-intercept at the ATE calculated in **step 1** over the range [`min(prop.cutoff)`,`max(prop.cutoff)`] (*y*) and the validation curve calculated in **step 2** (*x*).


The function `plot()` allows the user to combine validation curves from 2 or more CV iterations (i.e., `cv.n > 1`). There are 2 ways to combine the validation curves:

1. The option `combine`="median" takes the median of the ATEs across all CV iterations in **step 1** and the median of the ATEs in the 100 nested subgroups in **step 2**. 

2. The option `combine`="mean" takes the mean of the ATEs across all CV iterations in **step 1** and the mean of the ATEs in the 100 nested subgroups in **step 2**. 

In either case, the ABC calculations are carried out as in **step 3** with the resulting *x* and *y*.


The figure below explains how the ABC is calculated with a simple schema. The ABC calculations are such that larger positive ABC values always indicate more treatment effect heterogeneity. This is implemented by considering separately the cases when larger or smaller outcomes are preferred.

* If larger count outcomes are preferred (`higher.y = TRUE`, e.g., positive events like number of motor developmental milestones reached), a validation curve above the ATE line and decreasing towards that line is synonym with treatment effect heterogeneity (top left figure). However, sections of the validation curve below the ATE line indicate inability to capture treatment effect heterogeneity (bottom left figure). Hence, the ABC is defined by subtracting the areas below the ATE line (red) from the areas above the ATE line (green) such that larger positive ABC are preferred.

* If smaller count outcomes are preferred (`higher.y = FALSE`, e.g., negative events like number of relapses), a validation curve below the ATE line and increasing towards that line is synonym with treatment effect heterogeneity (top right figure). However, sections of the validation curve above the ATE line indicate inability to capture treatment effect heterogeneity (bottom right figure). Hence, the ABC is defined by subtracting the areas above the ATE line (red) from the areas below the ATE line (green) such that larger positive ABC are preferred. 

![ABC calculation examples in relation with `higher.y` argument in `cv()` and `pm()`. Validation curves are represented with a blue line and the dashed line is the ATE.](assets/ABCexample.png)

# References
