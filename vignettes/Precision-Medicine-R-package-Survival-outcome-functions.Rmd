---
title: "R package for precision medicine<br> survival outcome" 
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  rmarkdown::html_vignette:
    toc: TRUE
    number_sections: TRUE
    toc_depth: 3
    fig_caption: yes
    fig_width: 10
    fig_height: 6
    bookdown::html_document2: default
bibliography: assets/references.bib
link-citations: yes
theme: lumen
vignette: >
 %\VignetteIndexEntry{R package for precision medicine - survival outcome}
 %\VignetteEngine{knitr::knitr}
 \usepackage[utf8]{inputenc}
---

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("assets/sticker4.jpg"), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:10px; padding:0px;',
               width = "300px",
               heigth = "300px")
```

# Introduction
**PrecMed** provides a workflow for estimating and internally validating conditional average treatment effects (CATEs) from either randomized controlled trials (RCTs) or real-world data between two treatments. The CATE score, also known as the individualized treatment response score, is a continuous scalar for each subject which represents an expected individual-level treatment contrast, e.g., a difference or ratio of potential outcomes. It is used to explore *treatment effect heterogeneity* by distinguishing between potential subgroups with different average treatment effect (ATE). The CATE score can be estimated using various scoring methods depending on the type of outcome. `PrecMed` has 3 built-in validation metrics (area between curves [ABC], validation curves, and box plots) to internally evaluate the performance of different scoring methods with repeated cross-validation (CV).

`PrecMed` accepts count and survival outcomes only, and this vignette focuses on survival outcomes. For survival outcomes, the CATE is expressed as a ratio of expected restricted mean time lost (RMTL). Five methods have been implemented to calculate the CATE scores for survival outcomes: random forest, boosting, naive Poisson, two regressions, and contrast regression (@yadlowsky2020estimation). Two and contrast regressions are doubly robust estimation methods which leverage estimation of the propensity score (PS), whereas the 3 other methods are naive plug-in methods where the outcome is predicted based on separate models trained in each treatment arm. Extensions to continuous and longitudinal outcomes are work-in-progress, as well as extensions to more than two treatments. Stay tuned.  

The main functions of the package are: `pm()`, `cv()`, `abc()`, `plot()`, `boxplot()`, `dr.inference()`. The recommended workflow of analyses to identify treatment effect heterogeneity with several candidate scoring methods follows the steps below:

1. Compare up to 5 methods to construct the CATE score via internal validation (function `cv()`).  

2. Select the best method using 3 metrics:

    2.1 Compare the ABC across methods (function `abc()`).
  
    2.2 Compare the steepness of the validation curves in the validation samples across methods (function `plot()`).
  
    2.3 Compare the distribution of the ATE in mutually exclusive subgroups in the validation samples (function `boxplot()`).
  
3. For the selected method, estimate the CATE score in the entire data or, ideally, in an external dataset (function `pm()`). Steps 1 & 2 can be skipped if comparing and selecting methods are not of interest.  

4. Optional. Use `dr.inference()` to estimate ATE between two treatment groups with a doubly robust estimator and estimate the variability of the ATE with a bootstrap approach. 


This vignette has 3 main sections:

1. [Examples](#examples): Practical demonstration of `PrecMed` with a built-in toy example

2. [Function description](#fundescr): Detailed descriptions of the function, usage, arguments, returned values, and references

3. [Theoretical details](#theodetail): Theoretical background of the scoring method as well as the estimation of CATE and ATE

All abbreviations used in this vignette can be found in the [Abbreviations](#abbrev) section.

  
# Abbreviations {#abbrev}

Abbreviation        Full Name
-------------       ----------
ABC                 Area between curves
ATE                 Average treatment effect
CATE                Conditional average treatment effect
contrastReg         Contrast regression
CV                  Cross-validation
GAM                 Generalized additive model
GBM                 Gradient boosting machine
PM                  Precision medicine
PS                  Propensity score 
RCT                 Randomized controlled trial
RF                  Random forest
RMST                Restricted mean survival time
RMTL                Restricted mean time lost
twoReg              Two regressions

# Main example of the entire workflow {#examples}
```{r setup, include=FALSE}
###################################################################
#
# Project: Comprehensive R package for precision medicine
#
#
# Objective: Demonstrate the main features of the survival outcome functions
#
#
# Contributors: Phoebe Jiang, Gabrielle Simoneau
#
#
# Modifications:
#
#   Date			By			Description
# --------		--------	-----------------------------
#  15DEC2021  pj      Start the script
#  30MAR2022  pj      Add the new sticker
#  13APR2022  pj      Add cv example
#  19APR2022  gs      Review existing text
#                     Add plot and boxplot (with more score methods)
#  26APR2022  gs      Start theoretical details section
#             gs      Finish theoretical details
#  03MAY2022  pj      Add pm example
#  10MAY2022  gs      Review pm example & bug fix
#  18MAY2022  gs      Add dr.inference example
#  02JUN2022  pj      Add more examples
#  08JUN2022  gs      Minor edits
#  08JUN2022  pj      Add subgroup proportion to more example
#  15JUN2022  pj      Change back to 5 CV iterations in subgroup prop more example section
#  11JUL2022  gs      Added cv() function description
#  14JUL2022  pj      Add more examples (IPCW model, method, truncation time, follow up time)
#  20JUL2022  pj      Minor edits
#  22JUL2022  gs      Add drinf function description
###################################################################

options(mc.cores = 2) # R CMD check allows at most two cores
knitr::opts_chunk$set(echo = TRUE)
library(PrecMed)
library(ggplot2)
library(dplyr)
```

## Example data set

We use the following simulated data to demonstrate the `PrecMed` functions for survival outcomes. The data set `survivalExample` was simulated based on real-world claims data in multiple sclerosis and has 4,000 observations and 9 variables. 

* We will use `y` as the survival outcome, which is the number of days until the first relapse or censoring, whichever comes first. 

* We will use `d` as the event indicator, where $1$ represents an event and $0$ represents censoring. The censoring rate is about 84\%.

* We will use `trt` as the treatment variable, which has 2 drugs (drug0 and drug1). 

* The rest of the variables are baseline patient characteristics. Variable `age` is centered at 48 years old. The medical costs in the year prior to treatment initiation `previous_cost` is centered at 14,362 USD and scaled with standard deviation 24,266 USD.

```{r data, echo = F, eval = T, include = T}
str(survivalExample)
```

## Installation

<!-- TODO: change it to CRAN or github later. -->

```{r install, echo = T, eval = F}
library(devtools)
# install.packages(".../PrecMed_0.1.2.tar.gz", repos = NULL)
install.packages("C:/Users/gsimonea/OneDrive - Biogen/Desktop/PrecMed_0.1.2.tar.gz", repos = NULL)
```

## Internal validation via `cv()` {#cvsurvexample}

We first run the internal validation to compare 5 scoring methods. This is done with the function `cv()`. This first step gives results in the form of a "PrecMed" object which will be used in the next steps to compare the performance of the scoring methods.
 
The mandatory arguments in `cv()` are `response`, `cate.model`, `ps.model`, `data`, and `score.method`. They must be specified by the user. 

* The `response` argument specifies the type of outcome in the data. For survival outcomes, `response` = "survival". This informs the function of the necessary arguments and methods to use. 

* The argument `cate.model` specifies the CATE model as a formula, with the survival object from the `survival` package, `Surv(y, d)`, supplied on the left-hand side and the explanatory covariates supplied on the right-hand side. In the example below, we chose to specify to CATE as a linear combination of the following covariates: age, sex, medical costs in the year prior to treatment initiation, and number of relapses in the year prior to treatment initiation. Non-linear or interaction terms could also be included. Note that the treatment variable is not supplied in `cate.model` since this is an outcome model.

* The `ps.model` argument specifies the PS model as a formula, with the treatment variable `trt` on the left-hand side and the covariates (age and previous treatment in this example) on the right-hand side. The variable `trt` must be supplied as a numeric variable taking only 2 values, "1" for active treatment and "0" for control or comparator. If it is not the case, `cv()`  will stop with error if  `trt` takes more than 2 distinct values or will automatically transform `trt` into a numeric variable. In this example, `trt` (a factor variable taking values "drug0" and "drug1") was transformed and a warning message was left to the user (see output below): `Variable trt was recoded to 0/1 with drug0->0 and drug1->1`. If the data are from a RCT, it suffices to specify `ps.model` = trt ~ 1. Note that the PS model is only used in the estimation of the 2 doubly robust methods (two and contrast regressions).

* The argument `data` indicates the data frame in which the outcome, treatment and covariates specified in either `cate.model` or `ps.model` should be fetched.

* The `score.method` argument specifies the precision medicine (PM) methods to be used to calculate the CATE scores. There are a total of 5 scoring methods implemented:

  * `poisson` fits a Poisson model separately by treatment group.
  
  * `boosting` uses gradient boosted regression models (GBM) separately by treatment group.
  
  * `twoReg` implements the doubly robust two regressions estimator in @yadlowsky2020estimation.
  
  * `contrastReg` implements the doubly robust contrast regression estimator from @yadlowsky2020estimation.
  
  * `randomForest` fits a random forest model by treatment group. 

We also specified the following non-mandatory arguments to fit with the data and problem at hand: `ipcw.model`, `followup.time`, `tau0`, `surv.min`, `higher.y`, `initial.predictor.method`, `cv.n`, `plot.gbmperf`, `seed` and `verbose`.

* The `ipcw.model` argument specifies the inverse proability of censoring weighting (IPCW) model as a formula, with the left-hand side empty and the covariates on the right-hand side. The IPCW model calculates the probability of being censored as weights to be included in the PM methods in order to correct for right censoring. In the example below, we chose to specify IPCW model as a linear combination of age, medical costs in the year prior to treatment initiation, and previous treatment. This argument can be left default as `NULL` if the user wants to use the same covariates provided in the outcome model `cate.model` plus the treatment variable. 

* `followup.time` specifies the maximum follow-up time in the data. We set it default as `NULL`, which indicates unknown potential censoring time.

* `tau0` is the truncation time for defining restricted mean time lost (RMTL). We specified it as `NULL`, which automatically sets the truncation time as the maximum survival time in the data.

* `surv.min` truncates the censoring probability estimated from the IPCW model with a lower limit to prevent extremely small censoring probabilities. It is recommended to choose a small positive value close to 0. We chose `0.025` in the example, which corresponds to the default value. 

* `higher.y` was set to `TRUE` because relapse is a negative event and longer time to first relapse is more desirable in our example. Hence, we are telling the function that subgroups of high responders to drug1 vs drug0 should have later onset of the first relapse. In other situation, higher outcomes may be more favorable for time to a positive event, e.g., time to discharge or time to improved disability. It is important for this argument to match with the nature of `y` outcome because it will affect how the subgroups are defined by the CATE scores and the performance metrics. 

* `initial.predictor.method` specifies how predictions of the outcome are estimated in two regressions and contrast regression. Flexible models can be used such as GBM ("boosting"), random forests ("randomForest") or logistic regression ("logistic"). We chose "logistic" because it is relatively faster than boosting methods and random forest.

* We performed 5 CV iterations by specifying `cv.n` = 5. Typically, more CV iterations are desirable although associated with longer computational times.

* We avoided generating the boosting performance plots by specifying `plot.gbmperf` = FALSE.

* We set a random seed `seed` = 999 to reproduce the results.

* We only output the progress of the CV procedure (but not the full error messages and warnings) in the R console by setting `verbose` = 1.

There are many other non-mandatory arguments that `cv()` can accept. Please see the [More Examples](#moreexamples) section for more examples and the [Function description](#cvsurvdescr) section for details. If you run into errors or warnings with your data, it might be helpful to go over the descriptions to see if you need to alter the default values. In this toy example, we keep the default values of the remaining arguments.

```{r example_cv, eval = T, echo = T}
# Example
t0 <- Sys.time()
tau0 <- with(survivalExample,
             min(quantile(y[trt == "drug1"], 0.95), quantile(y[trt == "drug0"], 0.95)))
output_cv <- cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 5),
                prop.multi = c(0, 0.5, 0.6, 1),
                cv.n = 5,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 1)
t1 <- Sys.time()
t1 - t0
```

When `verbose` = 1, progress messages are printed in the R console but errors and warnings are not printed. The current CV iteration is printed, followed by the steps of the CV procedure (splitting the data, training the models, validating the models). A timestamp and a progress bar are also displayed upon completion of a CV iteration. If `contrastReg` was selected as one of the methods in `score.method`, an additional line of output message will indicate whether the algorithm has converged.

The output of `cv()` is an object of class "PrecMed" and here we named it `output_cv`. It carries the relevant information to use in the next step of the workflow which selects the method (among those specified in the argument `score.method`) capturing the highest level of treatment effect heterogeneity. The output, which is described below, will be used in the functions `plot()`, `boxplot()` and `abc()`.

For each method specified in the argument `score.method`, the following 4 groups of outputs are generated. We use the results from `randomForest` as an example.

**1\. ATEs in nested subgroups of high responders**

This output stores the ATEs - the ratio of RMTL between drug1 vs drug0 in this example - in nested subgroups of patients of high responders to drug 1 in the training (`$ate.est.train.high.cv`) and validation (`$ate.est.valid.high.cv`) sets across all CV iterations. When `higher.y` = TRUE for survival outcomes, which is the case in this example, lower CATE scores correspond to high responders to drug1. When `higher.y` = FALSE for survival outcomes, higher CATE scores correspond to high responders to drug1. Note that this is different for count outcomes. The direction of CATE scores depends on both `higher.y` and outcome type. 

```{r example_print_cv, eval = T, echo = T}
output_cv$ate.randomForest$ate.est.train.high.cv
output_cv$ate.randomForest$ate.est.valid.high.cv
```

The output is a matrix with columns corresponding to the CV iterations, labeled from 1 to `cv.n`, and rows corresponding to nested subgroups. The nested subgroups of patients are defined by the argument `prop.cutoff`. Here, we use `seq(0.6, 1, length = 5)` which defines  nested subgroups with the 60\%, 70\%, 80\%, 90\% and 100\% lowest (highest if `higher.y = FALSE`) CATE scores estimated by random forest. The rows in the output are labeled to reflect the user-specified proportions used to build the subgroups.

For example, in the training set and in the 4th CV iteration (4th column labeled "cv4"), the subgroup defined with the 80\% lowest CATE scores (4th row labeled "prop0.8") has an estimated RMTL ratio of `r round(output_cv$ate.randomForest$ate.est.train.high.cv[3,4], 3)`. In contrast, the subgroup defined with all patients (last row labeled "prop1") in the 4th CV iteration has an estimated RMTL ratio of `r round(output_cv$ate.randomForest$ate.est.train.high.cv[5,4], 3)`. <!-- This suggests that the CATE score estimated with random forests identifies high responders to drug 1 vs drug 0 because patients with the 50\% lowest estimated CATE score have a better (lower) RMTL ratio compared to all patients. If lower outcomes were preferable (as specified through the argument `higher.y`), subgroups would be defined with proportion of patients with *highest* estimated CATE score and *higher* RR would be better. -->

**2\. ATEs in nested subgroups of low responders**

This output stores the ATEs in nested subgroups of *low responders* to drug1 in the training (`$ate.est.train.low.cv`) and validation (`$ate.est.valid.low.cv`) sets across all CV iterations. When `higher.y` = TRUE for survival outcomes, higher CATE scores correspond to low responders to drug1. When `higher.y` = FALSE for survival outcomes, lower CATE scores correspond to low responders to drug1. Again, this is different for count outcomes. The direction of CATE scores depends on both `higher.y` and outcome type. 

```{r example_print_train_cv, eval = T, echo = T}
output_cv$ate.randomForest$ate.est.train.low.cv
```
The outputs are also matrices with columns corresponding to the CV iterations and rows corresponding to nested subgroups. 

The output for the low responders brings additional information to the user. It gives the ATEs in the complement of each nested subgroup of high responders. For example, the complement of the subgroup of high responders defined as patients with the 60\% lowest (highest if `higher.y` = FALSE) estimated CATE scores is the subgroup of low responders defined as patients with the 40\% highest (lowest if `higher.y` = TRUE) estimated CATE scores, labeled as "prop0.4". In the training set and in the first CV iterations, the estimated RMTL ratio is `r round(output_cv$ate.randomForest$ate.est.train.high.cv[2,1], 3)` in the 60\% high responders to drug 1 and `r round(output_cv$ate.randomForest$ate.est.train.low.cv[2,1], 3)` in the 40\% low responders. 

The 2 last rows have missing or infinite values and this can be due to many reasons. We record all errors and warnings and keep them as an element of the `cv` output. For example, we can use the following code to check specific errors and warnings of the first CV iteration (`$cv1`) using the random forest method (`$randomForest`) when estimating the ATE in the training sample in the low responder groups (`$est.train.low.cv`). It looks like there was no event observation in the 10% subgroup, possibly due to small sample size, which also relates to the convergence issue in the warning. Additionally, the warning for the 20% subgroup (``$warnings$'prop0.2'``) suggested that there was non-convergence of the Cox procedure and that the corresponding estimated ATE should be interpreted with caution.

```{r errwarn, eval = T, echo = T}
output_cv$`errors/warnings`$randomForest$est.train.low.cv$cv1
output_cv$`errors/warnings`$randomForest$est.valid.low.cv$cv1
```


**3\. ATEs in mutually exclusive multi-category subgroups**

This output stores the ATEs in mutually exclusive multi-category subgroups of patients in the training (`$ate.est.train.group.cv`) and validation (`$ate.est.valid.group.cv`) sets across all CV iterations. 

```{r example_print_group_cv, eval = T, echo = T}
output_cv$ate.randomForest$ate.est.train.group.cv
output_cv$ate.randomForest$ate.est.valid.group.cv
```

The output is a matrix with columns corresponding to the CV iterations and rows corresponding to the mutually exclusive subgroups. The previous 2 outputs only focus on binary subgroups (high or low responders). Here, the mutually exclusive subgroups can be more than 2 and are defined by the argument `prop.multi`. We use `c(0, 0.5, 0.6, 1)` which defines 3 subgroups of patients with the 50\% lowest, 10\% middle and 40\% highest estimated CATE scores when `higher.y` = TRUE (as in this example), or with the 40\% highest, 10\% middle and 50\% lowest estimated CATE scores when `higher.y` = FALSE. Taking the first column as an example, the first CV iteration calculated `r round(output_cv$ate.randomForest$ate.est.train.group.cv[1,1], 3)` as the RMTL ratio for the subgroup with the 50\% lowest estimated CATE scores, `r round(output_cv$ate.randomForest$ate.est.train.group.cv[2,1], 3)` as the RMTL ratio for the subgroup with the middle 10\% estimated CATE scores, and `r round(output_cv$ate.randomForest$ate.est.train.group.cv[3,1], 3)` as the RMTL ratio for the subgroup with the 40\% highest estimated CATE scores. Use ``output_cv$`errors/warnings`$randomForest$est.train.group.cv`` to learn more about the errors and warnings generated from these outputs.


## Comparison of methods with `abc()`

The ABC statistics is calculated by `abc()` for each scoring method specified in `cv()` and for each of the `cv.n` CV iterations using the output object `output_cv` from `cv()`. The ABC corresponds to the area between the curve formed by the ATEs in subgroups of high responders in the validation set (e.g., `output_cv$ate.randomForest$ate.est.valid.cv` for random forest) and the horizontal line representing the ATE in the validation set. A higher ABC value means that the method captures more treatment effect heterogeneity. 

```{r example_abc, eval = T, echo = T}
output_abc <- abc(x = output_cv)
output_abc
```

The output is a matrix with columns corresponding to the CV iterations and rows corresponding to the scoring methods specified in `score.method`. For example, random forest in CV iteration 1 has an ABC of `r round(output_abc[3,1], 3)`, which is the highest in this CV iteration, meaning that random forest offers the best performance in the first CV iteration. The user can combine the ABC for each method across iterations:

```{r example_abc_combine, eval = T, echo = T}
average_abc <- apply(output_abc, 1, mean)
average_abc
```
In this example, random forest also offers the best overall performance because it has the highest average ABC, followed closely by contrast regression.

## Visualization of the validation curves with `plot()`

The ATEs of nested subgroups of high responders to drug1 (e.g., `output_cv$ate.randomForest$ate.est.train.high.cv` and `output_cv$ate.randomForest$ate.est.valid.high.cv` for random forest) can be visualized as a side-by-side line plot, with training results on the left and validation results on the right. The x-axis is determined by `prop.cutoff` and the y-axis is the estimated ATEs averaged over `cv.n` CV iterations as specified by `cv.i` = NULL (default). The estimated ATE is expressed as a RMTL ratio of drug1 versus drug0 for our toy example. By default, the function retrieves the name of the treatment variable (`trt`) and the original labels (`drug0` and `drug1`) to specify a meaningful y-axis label. Otherwise, it is possible to customize the y-axis label via the `ylab`, for example, by specifying `ylab` = "RMTL ratio of drug1 vs drug0 in each subgroup". 

Steeper slopes indicate more treatment effect heterogeneity between drug1 and drug0. Because `higher.y` = TRUE in this example, the slopes should be increasing from left (`prop.cutoff` = 0.6) to right (`prop.cutoff` = 1) if treatment effect heterogeneity is present (see section [Validation curves and the ABC statistics](#ABCdetails) for illustration). The method that has the steepest slope in the validation results would be selected because it captures the most treatment effect heterogeneity while generalizing well to unseen data. 

 
```{r example_plot_lineplot1, eval = T, echo = T, fig.width = 11}
plot(x = output_cv)
```

For this toy example, the methods are performing well in the training data as per the steep, increasing slopes on the left plot. Moreover, all methods generalize well to the validation data, as indicated by the monotonous increasing curves in the validation data (right plot). The dashed gray line is the ATE in the entire data set, which is why all lines merge to this reference line when subgroup size is 100\% of the data (`prop.cutoff` = 1). For more explanation on the validation curves, see the [Function description](#plotdescr) section.

The  plot's legend includes the ABC statistics in the validation set. The user can choose to mute the ABC annotations by specifying `show.abc` = FALSE.

```{r example_plot_lineplot1.1, eval = T, echo = T}
plot(x = output_cv, 
     show.abc = FALSE, 
     ylab = c("RMTL ratio of drug1 vs drug0 in each subgroup"))
```

The user can choose to plot the validation curves of only 1 CV iteration instead of the average of all CV iterations. In the following example, we plot the validation curves of the second CV iteration by specifying `cv.i` = 2 and in grayscale by specifying `grayscale` = TRUE.

```{r example_plot_lineplot2, eval = T, echo = T}
plot(x = output_cv, 
     cv.i = 2, 
     grayscale = TRUE, 
     ylab = c("RMTL ratio of drug1 vs drug0 in each subgroup"))
```

The user can also choose to use the median (instead of mean [default]) of the ATEs across CV iterations by specifying the argument `combine` = "median" in `plot()`. 


## Visualization of the ATE in subgroups with `boxplot()` 

The ATEs of multi-category subgroups that are mutually exclusive can be visualized as box plots, with 1 box plot for each scoring method. Only validation results are visualized here. The x-axis is determined by `prop.multi` and the y-axis is the estimated ATEs in each subgroup. We specify the `ylab` argument accordingly. The subgroups correspond to each row of the `ate.est.valid.group.cv` result in `output_cv`, so in this example the subgroups are patient with the 50\% lowest (0-50\%), middle 10\% (50-60\%), and highest 40\% (60-100\%) estimated CATE scores. Notice that the groups do not have to be equally spaced in terms of percentiles. The box plot shows the distribution of the ATEs over all `cv.n` CV iterations, instead of a summary statistics like mean or median in `plot()`. 

```{r example_plot_boxplot, eval = T, echo = T}
boxplot(x = output_cv,
        ylab = "RMTL ratio of drug1 vs drug0 in each subgroup")
```

For this toy example, we can see why random forest and contrast regression methods have the 2 highest ABC and perform the best in the validation curves in the previous sections. They both have the most distinctive decreasing RMTL ratio as we go from the subgroup with the 50\% lowest CATE scores (red) to subgroup with the 40\% highest CATE scores (blue). This implies that there is some evidence of heterogeneous treatment effect and that the CATE scores estimated with random forest or contrast regression can capture it. They also have relatively smaller variation as the boxes are thinner. In comparison, the other 3 methods also present this increasing trend in the box plots, but we observe a larger variation in the RMTL ratio, especially with boosting. We can see that the box plots correspond to the other 2 outputs, `abc()` and `plot()`. Note that the y-axis can have different scales for different scoring methods.

<br><br>

> So far we provided 3 different metrics to summarize, visualize, and evaluate the `cv()` outputs. The user is encouraged to choose their own way of data wrangling that fits to their particular situation. 

<br><br>

## Estimation of the CATE score with `pm()` 

If no internal validation is needed or the user has chosen the scoring methods wanted, we can fit the PM methods directly to the entire given dataset and get the CATE score and ATE results. This is done with the function `pm()`. 

In general, `pm()` has similar arguments as `cv()`. The mandatory arguments are the same: `response`, `cate.model`, `ps.model`, `data`, and `score.method`, and they must be specified by the user. The user can also specify the non-mandatory arguments to fit with the data and problem at hand. Please see the [Function description](#pmsurvdescr) section for details. Because there is no internal validation, `pm()` does not have the `cv.n`, `train.prop`, `abc`, and `prop.multi` arguments. This is the main distinction between these 2 output functions. We specified the mandatory and non-mandatory arguments the same way as `cv()` in the example for demonstration purpose. 

If you run into errors or warnings with your data, it might be helpful to go over the descriptions to see if you need to alter the default values. In this toy example, we keep the default values of the remaining arguments.


```{r example_pm, eval = T, echo = T}
# Example
t0 <- Sys.time()
tau0 <- with(survivalExample,
             min(quantile(y[trt == "drug1"], 0.95), quantile(y[trt == "drug0"], 0.95)))
output_pm <- pm(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female 
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                higher.y = TRUE,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE)
t1 <- Sys.time()
t1 - t0
```

Despite the similar arguments, the outputs of `pm()` and `cv()` differ. Each method specified in `score.method` has the following sets of results in `pm()`: 

1. `score` contains the log-transformed estimated CATE scores for each subject. The CATE score is a linear combination of the variables specified in the `cate.model` argument. Same as the outcome, lower CATE scores are more desirable if `higher.y` = FALSE and vice versa. In our example, the survival outcome is time to first relapse, which is a negative event, so higher values indicate later onset of the first relapse. Hence, we specify `higher.y` = TRUE in the example. Each subject has 1 CATE score so the length of this output is 4,000 for our toy example. Below we show the CATE scores estimated with contrast regression for the first 6 subjects in the data. 

```{r print_pm.score, eval = T, echo = T}
length(output_pm$score.contrastReg)
head(output_pm$score.contrastReg)
```

2. `coefficients` contains the estimated coefficients of the CATE score for each scoring method. It is a data frame of the covariates (including intercept) as rows and scoring methods as columns. In our toy example, there are 4 covariates in the `cate.model`, plus the intercept, so there are 5 rows of estimated coefficients within each column. Boosting method does not estimate coefficients (it directly predicts the score) so they do not have coefficient results here.

```{r print_pm.coefs, eval = T, echo = T}
output_pm$coefficients
```

We can define the estimated CATE scores for contrast regression like shown below. The user can use this information to study the influence of each covariate. 
$$ 
\begin{aligned}
\widehat{CATE} = 0.25 & - 0.19 \times \text{age} \\
& + 0.15 \times \text{female (vs male)} \\ 
& + 0.56 \times \text{previous medical costs} \\
& + 0.39 \times \text{previous number of relapses} 
\end{aligned} $$

3. `ate` contains estimated ATEs by each nested subgroup of high responders to drug 1 defined by `prop.cutoff`. The subgroups are defined based on the estimated CATE scores with the specified scoring method. In this example, we show the estimated ATEs of subgroups identified by CATE scores of the contrast regression. For example, the estimated ATE for the subgroup of subjects constructed based on the 50\% ("prop0.5") lowest CATE scores estimated from the contrast regression is `r round(output_pm$ate.contrastReg[1], 2)`. 
```{r print_pm.ate, eval = T, echo = T}
output_pm$ate.contrastReg
```

You are encouraged to summarize and visualize the outputs in whichever way that fits their particular situation outside the package's functions. For example, it is possible to plot the densities of all CATE scores with `ggplot`. There are some subjects with extremely high estimated CATE scores but most of the samples fall between -10 and 10.

```{r plot_score, eval = T, echo = T, fig.align='center'}
dataplot <- data.frame(score = factor(rep(c("Random Forest", "Boosting", "Naive Poisson", 
                                            "Two regressions", "Contrast regression"), 
                                          each = length(output_pm$score.boosting))), 
                       value = c(output_pm$score.randomForest, output_pm$score.boosting, 
                                 output_pm$score.poisson, output_pm$score.twoReg, 
                                 output_pm$score.contrastReg))

dataplot %>% 
  ggplot(aes(x = value, fill = score)) + 
  geom_density(alpha = 0.5) +
  theme_classic() + 
  labs(x = "Estimated CATE score", y = "Density", fill = "Method")
```

## Estimation of the ATE with `dr.inference()` 

Beyond exploring treatment effect heterogeneity, `dr.inference()` allows estimating the ATE in terms of RMTL and HR. The RMTL estimator is doubly robust, meaning that the estimator is consistent if the PS model (argument `ps.model`) or the outcome model (argument `cate.model`) or both are correctly specified. The estimator also depends on the estimation of IPCW. The HR estimator is based on a Cox regression model. The function also provides standard error, confidence intervals, and p-values based on bootstrap.

The mandatory arguments are: `response`, `cate.model`, `ps.model`, and `data`. Those arguments have the same definitions as in `cv()` and `pm()`.

```{r run_dr.inference, eval = T, echo = T}
output_dr <- dr.inference(response = "survival",
                          cate.model = survival::Surv(y, d) ~ 
                            age + female + previous_cost + previous_number_relapses,
                          ps.model = trt ~ age + previous_treatment,
                          ipcw.model = NULL,
                          data = survivalExample,
                          followup.time = NULL,
                          tau0 = tau0,
                          surv.min = 0.025,
                          ipcw.method = "breslow",
                          ps.method = "glm", minPS = 0.01, maxPS = 0.99, 
                          n.boot = 500, verbose = 1, 
                          plot.boot = FALSE, seed = 999)
```

When `verbose` = 1, the function outputs 10 times the number of bootstrap iterations completed in the console. Since `n.boot` = 500, the number of bootstrap iterations are shown as a multiple of 50 in the example code.

```{r print_dr.inference, eval = T, echo = T}
output_dr
```

The output of `dr.inference()` shows the point estimate, standard error ("SE"), lower ("CI.lower") and upper ("CI.upper") bound of the 95\% confidence interval, and the p-value ("pvalue") for 4 estimands:

* the restricted mean survival time under drug 1 (`$rmst1`) 

* the restricted mean survival time under drug 0 (`$rmst0`)

* the log RMTL ratio (`$log.rmtl.ratio`), which is the log of the ratio of `tau0` - `$rmst1` divided by `tau0` - `$rmst0`

* the log HR (`$log.hazard.ratio`).

For example, the log RMTL ratio of `r round(output_dr$log.rmtl.ratio$estimate, 2)` and the 95\% confidence interval of (`r round(output_dr$log.rmtl.ratio$CI.lower, 2)`, `r round(output_dr$log.rmtl.ratio$CI.upper, 2)`) are displayed in the output. The user can retrieve the RMTL ratio to facilitate the interpretation:

```{r rmtl_dr.inference, eval = T, echo = T}
rmtl.ratio <- exp(output_dr$log.rmtl.ratio$estimate)
rmtl.ratio
CI.rmtl.ratio <- exp(output_dr$log.rmtl.ratio$estimate + c(-1, 1) * qnorm(0.975) * sqrt(output_dr$log.rmtl.ratio$SE))
CI.rmtl.ratio
```

The RMTL ratio of `r round(rmtl.ratio, 2)` along with the 95\% confidence interval of (`r round(CI.rmtl.ratio[1], 2)`, `r round(CI.rmtl.ratio[2], 2)`) suggest that drug 1 is superior to drug 0 because the ratio is significantly greater than 1.

The output of `dr.inference()` is expressed in terms of treatment 0 vs 1, where the RMTL and hazard ratios are expressed as the ratio of the treatment coded as 1 over the treatment coded as 0. If the treatment variable is not coded as 0/1 in the data set, the function returns a warning `output_dr$warning` which indicates what key was used to recode the treatment variable into a 0/1 variable.

```{r warning_dr.inference, eval = T, echo = T}
output_dr$warning
```

When `plot.boot` = TRUE, the output provides histograms `$plot` of the point estimates across the `n.boot` bootstrap iterations for 4 estimands (`rmst1`, `rmst0`, `log.rmtl.ratio`, `log.hazard.ratio`). A red vertical line is added to each histogram with the mean of the bootstrap estimates. Moreover, when `plot.boot` = TRUE and `verbose` = 1, the histogram is displayed in the console and updated at each 10\% bootstrap iterations. For example, when `n.boot` = 500, the updated histogram is shown every 50 bootstrap iterations.

![Figure. Histograms of bootstrap estimators for 4 estimands after 500 bootstrap iterations](assets/drinference_bootstrap.png)

# More examples {#moreexamples}
**PrecMed** can be flexible given the many arguments that the user can specify. The example described above is one of the many ways to perform the analysis with most argument values kept as default. We provide a few more examples below to show what other options the user has and how to be more creative in using **PrecMed**. 

## Initial predictor method
If you choose two and/or contrast regression as the scoring method, there is an option to specify how the initial outcome regression estimates ($\hat\mu_r^k$ where $r = 0,1$ is the treatment and $k$ is the cross validation fold) are calculated. See [Theoretical details](#theodetail) section for the background of these initial predictors and how they are used in the two and contrast regression. Here is a list of all 3 options:

* "logistic" (logistic regression from the `glm()` function) 
  * generalized linear model, strong assumption on binomial distribution, fast
* "boosting" (gradient boosting machine from the `gbm` R package)
  * ensemble method, typically tree-based, assume the time-to-event outcome as Gaussian distributed, slow
* "randomForest" (random survival forest model from the `randomForestSRC` package)
  * ensemble method, tree-based, non-parametric, can be slow

The main example above used a logistic regression but you can try the other 2 non-linear and more flexible options. Below, we use `cv()` as the example code but this can be applied to `pm()` as well. 

```{r initial_predictor_gbm_gam, eval = F, echo = T}
# An example of using GBM as the initial predictor method
cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 5),
                prop.multi = c(0, 0.5, 0.6, 1),
                cv.n = 5,
                initial.predictor.method = "boosting", # NEW
                tree.depth = 3,                        # NEW
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 0)

# An example of using random forest as the initial predictor method
cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 5),
                prop.multi = c(0, 0.5, 0.6, 1),
                cv.n = 5,
                initial.predictor.method = "randomForest", # NEW
                n.trees.rf = 500,                          # NEW
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 0)
```

Note that for `boosting` and `randomForest` methods that are tree-based, parameters such as tree depth and number of trees can be specified with arguments `tree.depth`,  `n.trees.rf`, and `n.trees.boosting`. 

Generally speaking, the "logistic" initial predictor method is the fastest and "boosting" is the slowest among the 3 methods, while "randomForest" is somewhere in between with longer computational time as the number of trees and tree depth increase.




## Subgroup proportion
The **PrecMed** results depend on the subgroups which are determined by the sorted CATE scores. There could be nested binary subgroups (cutoffs specified by `prop.cutoff`) or mutually exclusive subgroups (cutoffs specified by `prop.multi`). In the main example above, we used certain values of `prop.cutoff` and `prop.multi` and we have provided explanations in the ATE results. Here is a recap:

* `prop.cutoff = seq(0.6, 1, length = 5)` means that we have 5 sets of nested binary subgroups where the first subgroup set is split by 60/40 according to the estimated CATE scores (sorted), the 2nd subgroup set is split by 70/30, ..., and the 6th subgroup set is split by 100/0. The validation curves show results of the first group of each split, i.e., 60%, 70%, ..., 100%. The 5th subgroup set is technically not a split but we keep it because it is equivalent to the overall ATE (the gray dashed reference line). **PrecMed** will automatically discard 0 if supplied because 0/100 split does not make sense as there is no 0% subgroup to plot for the validation curves, and a warning message will be given. Argument `higher.y` controls the direction of the sorted CATE scores, i.e., whether we split from the lowest or the highest CATE scores. For our toy example, `higher.y` = TRUE so we split from the lowest CATE scores.

* `prop.multi = c(0, 0.5, 0.6, 1)` means that we specify a 3-category mutually exclusive subgroup, split by 50/10/40 according to the estimated CATE scores. Argument `higher.y` controls the direction of the sorted CATE scores, i.e., where we split from the lowest or the highest CATE scores. For our toy example, `higher.y` = TRUE so we split from the lowest CATE scores. Contrary to `prop.cutoff`, `prop.multi` must include both 0 and 1 to remind us of the mutual exclusiveness. **PrecMed** will automatically attach 0 and/or 1 if they are not supplied and a warning message will be given. 

Now we show more examples of different cutoffs and how they are reflected in the results. 

```{r subgroup_proportion, eval = T, echo = T}
# An example of 9 nested binary subgroups and a 4-category mutually exclusive subgroup
output_cv2 <- cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 9), # NEW
                prop.multi = c(0, 0.4, 0.5, 0.6, 1),   # NEW
                cv.n = 5,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 0)
```
```{r subgroup_proportion2, eval = T, echo = T}
print(output_cv2$ate.contrastReg$ate.est.train.high.cv) 
# Dimension is 9 (nested binary subgroups) by 5 (CV iterations)
```

Because we have new `prop.cutoff` with 9 values as opposed to only 5 in the original example, the number of rows in the ATE results will be changed accordingly while the number of columns remains to be 5. 


```{r subgroup_proportion3, eval = T, echo = T}
plot(output_cv2) 
```

The validation curves depend on `prop.cutoff` and have more line segments than the one presented in the main example because they contain 9 sets of subgroups instead of 5 sets (although it is not so obvious here in this example). The ABC statistic is not affected by this because the calculation of ABC statistics depends on the minimum and maximum of the `prop.cutoff` vector and 100 evenly-spaced subgroup cutoffs are created from this range. The highest proportion cutoff that is not 1 in the main example was 0.9 and it is now 0.95. See more theoretical details on ABC calculation in the [Theoretical details](#ABCdetails) section. 


```{r subgroup_proportion4, eval = T, echo = T}
print(output_cv2$ate.contrastReg$ate.est.train.group.cv) 
# Dimension is now 4 (multi-category mutually exclusive subgroups) by 3 (CV iterations)

boxplot(output_cv2)
```

For results on the mutually exclusive subgroups, the number of rows in the ATE results increases from 3 to 4 in comparison with the original example because `prop.multi` now defines 4 mutually exclusive subgroups. For each methods, the box plot now has 4 boxes for 4 mutually exclusive subgroups.


**Examples that we do not recommend**

In this example, `prop.cutoff` includes 0.1. Consequently, the scoring methods may run into some convergence issues because the first subgroup includes a small number of patients. This can lead to highly unstable ATE estimates or calculation error as the error message below shows. 

```{r subgroup_proportion_bad, eval = T, echo = T, error = T}
# An example of very few nested binary subgroups
output_cv3 <- cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = NULL,
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                higher.y = TRUE,
                prop.cutoff = c(0, 0.1, 0.75, 1), # NEW
                prop.multi = c(0, 0.5, 0.6, 1),
                cv.n = 5,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 1)

```


Below are some general recommendations on the choice of `prop.cutoff` and `prop.multi`:

1. We do not recommend including 0 in `prop.cutoff` as it is an invalid value. **PrecMed** automatically removes 0 in `prop.cutoff` and outputs a warning message.
2. We do not recommend choosing values too close to 0 either because this will generate very small subgroups which may lead to numerical instability, e.g., 10/90 split specified by 0.1 in this example. In this situation, either the validation curves will be plotted by the range of the unstable ATE estimates will make them useless or the validation curves will not be plotted if the numerical instability due to an extreme split leads to missing or infinite values, in which case a warning or error is printed as in the example above. 
3. In general, we do not recommend specifying too few proportions for `prop.cutoff` (e.g., 2 or 3) because the validation curves will look very jagged. The validation curves will be smoother with more proportions and more spread out over the range of proportions. If computation is an issue, however, choosing too many values for `prop.cutoff` or `prop.multi` can be time consuming. It is recommended to start from a smaller length and you can increase the length as needed. 

## IPCW model and method

The default IPCW model uses the same covariates as the outcome model `cate.model` plus the treatment. The default IPCW method is a Cox regression with Breslow estimator of the baseline survivor function from `coxph()` function in the `survival` package. Different variables or different method can be specified in the IPCW model. In the example below, we changed the covariates to the number of symptoms and number relapses in the pre-index period and specified the Weibull accelerated failure time (AFT) regression model using the location-scale parameterization. The `survreg()` function in the `survival` package was used to fit the AFT model. 

```{r ipcw, eval = F, echo = T}
# An example of a different IPCW model with different covariates from default
output_cv4 <- cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = ~ previous_number_symptoms + previous_number_relapses,          # NEW
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = tau0,
                surv.min = 0.025,
                ipcw.method = "aft (weibull)",                                               # NEW
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 5), 
                prop.multi = c(0, 0.5, 0.6, 1),  
                cv.n = 5,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 0)
```

## Truncation and follow-up time
The argument `tau0` specifies the truncation time for RMTL. The default is the maximum survival time in the data but it can be changed if you have a specific truncation time in mind. Similarly, the maximum follow-up time argument `followup.time` can be changed from the default, which is unknown potential censoring time. The study setup usually can shed some light on what values to use for these two time parameters. 

In the main example, we used the minimum of the 95th percentile of survival time in either treatment group as `tau0`. Below we show how setting different values of the truncation time.

```{r time, eval = T, echo = T}
# An example of a different IPCW model with different covariates from default
output_cv5 <- cv(response = "survival",
                cate.model = survival::Surv(y, d) ~ age + female
                                                        + previous_cost + previous_number_relapses,
                ps.model = trt ~ age + previous_treatment,
                ipcw.model = ~ previous_number_symptoms + previous_number_relapses,          
                data = survivalExample,
                score.method = c("poisson", "boosting", "randomForest", "twoReg", "contrastReg"),
                followup.time = NULL,
                tau0 = NULL,                                                             # NEW
                surv.min = 0.025,
                ipcw.method = "aft (weibull)",                                               
                higher.y = TRUE,
                prop.cutoff = seq(0.6, 1, length = 5), 
                prop.multi = c(0, 0.5, 0.6, 1),  
                cv.n = 5,
                initial.predictor.method = "logistic",
                seed = 999,
                plot.gbmperf = FALSE,
                verbose = 0)
plot(output_cv5)
```

# Function description {#fundescr}

## `cv()`{#cvdescr}

### Description {.unlisted .unnumbered}

Provides (doubly robust) estimation of the ATE for count or survival outcomes in nested and mutually exclusive subgroups of patients defined by an estimated CATE score via CV.

### Usage {.unlisted .unnumbered}

```{r cvsurv, eval = F, echo = T}
cv(
  response, 
  cate.model, 
  ps.model, 
  data, 
  score.method,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  higher.y = TRUE, 
  abc = TRUE, 
  prop.cutoff = seq(0.5, 1, length = 6), 
  prop.multi = c(0, 1/3, 2/3, 1),
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99,
  train.prop = 3/4, 
  cv.n = 10, 
  error.max = 0.1, 
  max.iter = 5000,
  initial.predictor.method = NULL, 
  xvar.smooth = NULL,
  tree.depth = 2, 
  n.trees.rf = 1000, 
  n.trees.boosting = 200, 
  B = 3, 
  Kfold = 5,
  error.maxNR = 1e-3, 
  max.iterNR = 150, 
  tune = c(0.5, 2),
  seed = NULL, 
  plot.gbmperf = TRUE, 
  verbose = 2
  )
```

### Arguments {.unlisted .unnumbered}

Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `cvcount()`) and "survival" (see `cvsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`score.method`          A vector of one or multiple methods to estimate the CATE score. Allowed values are: "boosting", "poisson", "twoReg", "contrastReg", "negBin" (count outcomes only), and "randomForest" (survival outcomes only).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`higher.y`              A logical value indicating whether higher (TRUE) or lower (FALSE) values of the outcome are more desirable. Default is TRUE.
`abc`                   A logical value indicating whether the ABC should be calculated at each CV iterations, for each `score.method`. Default is TRUE.
`prop.cutoff`           A vector of numerical values (in (0, 1]) specifying percentiles of the estimated log CATE scores to define nested subgroups. Each element represents the cutoff to separate observations in nested subgroups (below vs above cutoff). The length of `prop.cutoff` is the number of nested subgroups. An equally-spaced sequence of proportions ending with 1 is recommended. Default is `seq(0.5, 1, length = 6)`.
`prop.multi`            A vector of numerical values (in [0, 1]) specifying percentiles of the estimated log CATE scores to define mutually exclusive subgroups. It should start with 0, end with 1, and be of `length(prop.multi) > 2`. Each element represents the cutoff to separate the observations into `length(prop.multi) - 1` mutually exclusive subgroups. Default is `c(0, 1/3, 2/3, 1)`.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.
`train.prop`            A numerical value (in (0, 1)) indicating the proportion of total data used for training. Default is 3/4.
`cv.n`                  A positive integer value indicating the number of CV iterations. Default is 10.


Additional arguments            Description
---------------------           ------------
`ipcw.method`                   A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`error.max`                     A numerical value > 0 indicating the tolerance (maximum value of error) for the largest standardized absolute difference in the covariate distributions or in the doubly robust estimated rate ratios between the training and validation sets. This is used to define a balanced training-validation splitting. Default is 0.1.
`max.iter`                      A positive integer value indicating the maximum number of iterations when searching for a balanced training-validation split. Default is 5,000.
`initial.predictor.method`      A character vector for the method used to get initial outcome predictions conditional on the covariates specified in `cate.model`. Only applies when `score.method` includes "twoReg" or "contrastReg". Allowed values include one of "randomForest" (survival outcomes only), "boosting", "logistic" (survival outcomes only, fast), "poisson" (count outcomes only, fast), and "gam" (count outcomes only). Default is NULL, which assigns "boosting" for count outcomes and "randomForest" for survival outcomes.
`xvar.smooth`                   A vector of characters indicating the name of the variables used as the smooth terms if `initial.predictor.method` = "gam". The variables must be selected from the variables listed in `cate.model`. Only applies for count outcomes. Default is NULL, which uses all variables in `cate.model`.
`tree.depth`                    A positive integer specifying the depth of individual trees in boosting (usually 2-3). Used only if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 2.
`n.trees.rf`                    A positive integer specifying the maximum number of trees in random forest. Used if `score.method` = "ranfomForest" or if `initial.predictor.method` = "randomForest" with `score.method` = "twoReg" or "contrastReg". Only applies for survival outcomes. Default is 1000.
`n.trees.boosting`              A positive integer specifying the maximum number of trees in boosting (usually 100-1000). Used if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 200.
`B`                             A positive integer specifying the number of time cross-fitting is repeated in `score.method` = "twoReg" and "contrastReg". Default is 3.
`Kfold`                         A positive integer specifying the number of folds used in cross-fitting to partition the data in `score.method` = "twoReg" and "contrastReg". Default is 5.
`error.maxNR`                   A numerical value > 0 indicating the minimum value of the mean absolute error in Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 0.001.
`max.iterNR`                    A positive integer indicating the maximum number of iterations in the Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 150.
`tune`                          A vector of 2 numerical values > 0 specifying tuning parameters for the Newton Raphson algorithm. `tune[1]` is the step size, `tune[2]` specifies a quantity to be added to diagonal of the slope matrix to prevent singularity. Used only if `score.method` = "contrastReg". Default is `c(0.5, 2)`.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`plot.gbmperf`                  A logical value indicating whether to plot the performance measures in boosting. Used only if `score.method` = "boosting" or if `score.method` = "twoReg" or "contrastReg" and `initial.predictor.method` = "boosting". Default is TRUE.
`verbose`                       An integer value indicating what kind of intermediate progress messages should be printed. `0` means no outputs. `1` means only progress bar and run time. `2` means progress bar, run time, and all errors and warnings. Default is 2.


### Value {.unlisted .unnumbered}

For survival outcomes, the function returns a list containing the following components saved as a "PrecMed" object:

* **ate.randomForest**: A list of ATE output measured by the RMTL ratio if `score.method` includes "randomForest":

    * **ate.est.train.high.cv**: A matrix of numerical values with `length(prop.cutoff)` rows and `cv.n` columns. The ith row/jth column cell contains the estimated ATE in the nested subgroup of high responders defined by CATE score above (if `higher.y` = FALSE) or below (if `higher.y` = TRUE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **ate.est.train.low.cv**: A matrix of numerical values with `length(prop.cutoff) - 1` rows and `cv.n` columns. The ith row/jth column cell contains the estimated ATE in the nested subgroup of low responders defined by CATE score below (if `higher.y` = FALSE) or above (if `higher.y` = TRUE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **ate.est.valid.high.cv**: Same as `ate.est.train.high.cv`, but in the validation set.
    
    * **ate.est.valid.low.cv**: Same as `ate.est.train.low.cv`, but in the validation set.
    
    * **ate.est.train.group.cv**: A matrix of numerical values with `length(prop.multi) - 1` rows and `cv.n` columns. The jth column contains the estimated ATE in `length(prop.multi) - 1` mutually exclusive subgroups defined by `prop.multi` in the training set in jth CV iteration.
    
    * **ate.est.valid.group.cv**: Same as `ate.est.train.group.cv`, but in the validation set.
    
    * **abc.valid**: A vector of numerical values of length `cv.n`. The ith element returns the ABC of the validation curve in the ith CV iteration. Only returned if `abc` = TRUE.
    
* **ate.boosting**: A list of results similar to `ate.randomForest` output if `score.method` includes "boosting".

* **ate.poisson**: A list of results similar to `ate.randomForest` output `score.method` includes "poisson".

* **ate.twoReg**: A list of results similar to `ate.randomForest` output if `score.method` includes "twoReg".

* **ate.contrastReg**: A list of results similar to `ate.randomForest` output if `score.method` includes "contrastReg". This method has an additional element in the list of results:

    * **converge.contrastReg.cv**: A vector of logical value of length `cv.n`. The ith element indicates whether the algorithm converged in 

* **hr.randomForest**: A list of adjusted hazard ratio if `score.method` includes "randomForest":

    * **hr.est.train.high.cv**: A matrix of numerical values with `length(prop.cutoff)` rows and `cv.n` columns. The ith row/jth column cell contains the estimated HR in the nested subgroup of high responders defined by CATE score above (if `higher.y` = FALSE) or below (if `higher.y` = TRUE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **hr.est.train.low.cv**: A matrix of numerical values with `length(prop.cutoff) - 1` rows and `cv.n` columns. The ith row/jth column cell contains the estimated HR in the nested subgroup of low responders defined by CATE score below (if `higher.y` = FALSE) or above (if `higher.y` = TRUE) the `prop.cutoff[i]`x100% percentile of the estimated CATE score in the training set in the jth CV iteration.
    
    * **hr.est.valid.high.cv**: Same as `hr.est.train.high.cv`, but in the validation set.
    
    * **hr.est.valid.low.cv**: Same as `hr.est.train.low.cv`, but in the validation set.
    
    * **hr.est.train.group.cv**: A matrix of numerical values with `length(prop.multi) - 1` rows and `cv.n` columns. The jth column contains the estimated HR in `length(prop.multi) - 1` mutually exclusive subgroups defined by `prop.multi` in the training set in jth CV iteration.
    
    * **hr.est.valid.group.cv**: Same as `hr.est.train.group.cv`, but in the validation set.

* **hr.boosting**: A list of results similar to `hr.randomForest` output if `score.method` includes "boosting".

* **hr.poisson**: A list of results similar to `hr.randomForest` output `score.method` includes "poisson".

* **hr.twoReg**: A list of results similar to `hr.randomForest` output if `score.method` includes "twoReg".

* **hr.contrastReg**: A list of results similar to `hr.randomForest` output if `score.method` includes "contrastReg".

* **props**: A list of 3 elements:

    * **prop.onlyhigh**: The original argument `prop.cutoff`, reformatted as necessary.
    
    * **prop.bi**: The original argument `prop.cutoff`, similar to `prop.onlyhigh` but reformatted to exclude 1.
    
    * **prop.multi**: The original argument `prop.multi`, reformatted as necessary to include 0 and 1.

* **overall.ate.train**: A vector of numerical values of length `cv.n`. The ith element contains the ATE (RMTL ratio) in the training set of the ith CV iteration, estimated with the doubly robust estimator.

* **overall.hr.train**: A vector of numerical values of length `cv.n`. The ith element contains the ATE (HR) in the training set of the ith CV iteration, estimated with the doubly robust estimator.

* **overall.ate.valid**: A vector of numerical values of length `cv.n`. The ith element contains the ATE (RMTL ratio) in the validation set of the ith CV iteration, estimated with the doubly robust estimator.

* **overall.hr.valid**: A vector of numerical values of length `cv.n`. The ith element contains the ATE (HR) in the validation set of the ith CV iteration, estimated with the doubly robust estimator.

* **errors/warnings**: A nested list of errors and warnings that were wrapped during the calculation of ATE. Errors and warnings are organized by `score.method` and position in the CV flow.

* **higher.y**: The original `higher.y` argument.

* **abc**: The original `abc` argument.

* **cv.n**: The original `cv.n` argument.

* **response**: The type of response. Always "survival" for this function.

* **formulas**: A list of 3 elements: (1) `cate.model` argument, (2) `ps.model` argument and (3) original labels of the left-hand side variable in `ps.model` (treatment) if it was not 0/1.


### Details {.unlisted .unnumbered}

The CATE score represents an individual-level treatment effect expressed as the RMTL ratio for survival outcomes. It can be estimated with boosting, Poisson regression, random forest (survival only), and the doubly robust estimator two regressions (@yadlowsky2020estimation) applied separately by treatment group or with the other doubly robust estimator contrast regression (@yadlowsky2020estimation) applied to the entire data set.

Internal CV is applied to reduce optimism in choosing the CATE estimation method that captures the most treatment effect heterogeneity. The CV is applied by repeating the following steps `cv.n` times:

1. Split the data into a training and validation set according to `train.prop`. The training and validation sets must be balanced with respect to covariate distributions and doubly robust rate ratio estimates (see `error.max`).

2. Estimate the CATE score in the training set with the specified scoring method.

3. Predict the CATE score in the validation set using the scoring model fitted from the training set.

4. Build nested subgroups of treatment responders in the training and validation sets, separately, and estimate the ATE within each nested subgroup. For each element i of `prop.cutoff` (e.g., `prop.cutoff[i]` = 0.6), take the following steps:

    4.1. Identify high responders as observations with the 60% (i.e., `prop.cutoff[i]`x100%) highest (if `higher.y` = TRUE) or lowest (if `higher.y` = FALSE) estimated CATE scores.
    
    4.2. Estimate the ATE in the subgroup of high responders using a doubly robust estimator.
    
    4.3. Conversely, identify low responders as observations with the 40% (i.e., 1 - `prop.cutoff[i]`x100%) lowest (if `higher.y` = TRUE) or highest (if `higher.y` = FALSE) estimated CATE scores.
    
    4.4. Estimate the ATE in the subgroup of low responders using a doubly robust estimator.

5. If `abc` = TRUE, calculate the area between the ATE and the series of ATEs in nested subgroups of high responders in the validation set.

6. Build mutually exclusive subgroups of treatment responders in the training and validation sets, separately, and estimate the ATE within each subgroup. Mutually exclusive subgroups are built by splitting the estimated CATE scores according to `prop.multi`.

## `abc()`

### Description {.unlisted .unnumbered}
Compute the area between curves (ABC) for each scoring method in the \code{"PrecMed"} object. This should be run only after results of \code{cv()} have been obtained.

### Usage {.unlisted .unnumbered}

```{r abc, eval = F, echo = T}
abc(x)
```

### Arguments {.unlisted .unnumbered}

Main argument   Description
--------------  ------------
`x`             An object of class "PrecMed".

### Value {.unlisted .unnumbered}
Returns a matrix of numeric values with number of columns equal to the number of cross-validation iterations and number of rows equal to the number of scoring methods in `x`. 

### Details {.unlisted .unnumbered}
The ABC is the area between a validation curve and the overall ATE in the validation set. It is calculated for each scoring method separately. Higher ABC values are preferable as they indicate that more treatment effect heterogeneity is captured by the scoring method. Negative values of ABC are possible if segments of the validation curve cross the overall ATE line. The ABC is calculated with `auc()` in the `MESS` package with a natural cubic spline interpolation. The calculation of the ABC is always based on validation curves based on 100 proportions equally spaced from `min(prop.cutoff)` to `max(prop.cutoff)`.

The ABC is a metric to help users select the best scoring method in terms of capturing treatment effect heterogeneity in the data. It should be used in complement to the visual inspection of the validation curves in the validation set in `plot()`. See @zhao2013effectively.

## `plot()`{#plotdescr}

### Description {.unlisted .unnumbered}

Provides validation curves in two side-by-side plots, visualizing the estimated ATEs in a series of nested subgroups in the training set and validation set separately, where each line represents one scoring method specified in `cv()`. This should be run only after results of `cv()` have been obtained.

### Usage {.unlisted .unnumbered}

```{r plot, eval = F, echo = T}
plot(
  x,
  cv.i = NULL,
  combine = "mean",
  show.abc = TRUE,
  valid.only = FALSE,
  plot.hr = FALSE,
  ylab = NULL,
  legend.position = "bottom",
  grayscale = FALSE,
  xlim = NULL
  )
```

### Arguments {.unlisted .unnumbered}
Main argument         Description
--------------        ------------
`x`                   An object of class "PrecMed".

Additional arguments      Description
---------------------     ------------
`cv.i`                    A positive integer indicating the index of the CV iteration results to be plotted. Allowed values are: a positive integer $<=$ `cv.n` in `cv()` or NULL. If `cv.i` = NULL, the results across all CV iterations are combined according to `combine` and then plotted. Default is NULL.
`combine`                 A character value indicating how to combine the estimated ATEs across all CV iterations into a validation curve for each nested subgroup, separately for the training and validation results. Allowed values are: "mean" or "median". Used only if `cv.i` = NULL. Default is "mean".
`show.abc`                A logical value indicating whether to show the ABC statistics in the validation set. Used only if `x$abc` = TRUE and `xlim` is not limited to a smaller range (i.e., `xlim` = NULL or equal to the entire `x$prop.onlyhigh` range). If `cv.i` is NULL, ABC statistics will be based on the combined CV iterations. If `cv.i` is an integer, ABC statistics will be based solely on that CV iteration. Default is TRUE.
`valid.only`              A logical value indicating whether only the validation curves in the validation set should be plotted (TRUE). Otherwise, the validation curves in both the training and validation sets are plotted side-by-side (FALSE). Default is FALSE.
`plot.hr`                 A logical value indicating whether the hazard ratios should be plotted in the validation curves (TRUE). Otherwise, the restricted mean time lost is plotted (FALSE). This argument is only applicable to survival outcomes. Default is FALSE.
`ylab`                    A character value for the y-axis label to describe what the ATE is. Default is NULL, which creates a default y-axis label based on available data. 
`legend.position`         A character value for the legend position argument to be passed to `ggplot` object. Default is "bottom".
`grayscale`               A logical value indicating grayscale plots (TRUE) or colored plots (FALSE). Default is FALSE.
`xlim`                    A numeric value for the range of the x-axis. Default is NULL, which means there is no range specified.

### Value {.unlisted .unnumbered}
Returns two side-by-side line plots, one of which shows the validation curves of the training sets and the other the validation curves in the validation sets. A gray horizontal dashed line of overall ATE is included as a reference. ABC statistics will be added to the legend if `show.abc` = TRUE.

### Details {.unlisted .unnumbered}

`plot()` takes in outputs from `cv()` and generates two plots of validation curves side-by-side, one for the training set and one for validation set. Separate validation curves are produced for each scoring method specified `via score.method` in `cv()`.

The validation curves (and ABC statistics, if applicable) can help compare the performance of different scoring methods in terms of discerning potential treatment heterogeneity in subgroups with internal validation. Steeper validation curves in the validation set suggest presence of treatment effect heterogeneity (and the ability of the scoring methods to capture it) while flat validation curves indicate absence of treatment effect heterogeneity (or inability of the scoring method to capture it).

## `boxplot()`

### Description {.unlisted .unnumbered}

Provides box plots which depict distributions of estimated ATEs for each multi-category subgroup in the validation set across all cross-validation iterations. The subgroups are mutually exclusive and are categorized by the CATE score percentiles (`prop.multi` specified in `cv()`). Box plots of mutually exclusive subgroups are constructed separately by scoring method specified in `cv()`. This should be run only after results of `cv()` have been obtained.

### Usage {.unlisted .unnumbered}

```{r boxplot, eval = F, echo = T}
boxplot(
  x,
  ylab = NULL,
  plot.hr = FALSE,
  grayscale = FALSE
  )
```

### Arguments {.unlisted .unnumbered}

Main argument       Description
--------------      ------------
`x`                 An object of class "PrecMed".

Additional argument       Description
--------------------      ------------
`ylab`                    A character value for the y-axis label to describe what the ATE is. Default is NULL, which creates a default y-axis label based on available data. 
`plot.hr`                 A logical value indicating whether the hazard ratios should be plotted in the validation curves (TRUE). Otherwise, the restricted mean time lost is plotted (FALSE). This argument is only applicable to survival outcomes. Default is FALSE.
`grayscale`               A logical value indicating grayscale plots (TRUE) or colored plots (FALSE). Default is FALSE.

### Value {.unlisted .unnumbered}
Returns sets of box plots, one set for each scoring method, over each of the multi-category subgroups. A gray horizontal dashed line of the overall ATE is included as a reference.

### Details {.unlisted .unnumbered}
`boxplot()` takes in outputs from `cv()` and generates the box plots of estimated ATEs for multi-category subgroups of the validation set. The box plots together with the overall ATE reference line can help compare the scoring methods' ability to distinguish subgroups of patients with different treatment effects.

For a given scoring method, box plots showing increasing or decreasing trends across the multi-category subgroups indicate presence of treatment effect heterogeneity (and the ability of the scoring method to capture it). On the contrary, box plots which are relatively aligned across the multi-category subgroups indicate absence of treatment effect heterogeneity (or the inability of the scoring method to capture it).

## `pm()` {#pmsurvdescr}

### Description {.unlisted .unnumbered}

Provides singly robust and doubly robust estimation of CATE score for count and survival data with the following scoring methods: Random forest (survival only), boosting, poisson regression, two regressions, contrast regression, and negative binomial regression (count only).

### Usage {.unlisted .unnumbered}

```{r pmcount, eval = F, echo = T}
pm(
  response, 
  cate.model, 
  ps.model, 
  data, 
  score.method,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  higher.y = TRUE, 
  prop.cutoff = seq(0.5, 1, length = 6), 
  prop.multi = c(0, 1/3, 2/3, 1),
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99,
  initial.predictor.method = NULL, 
  xvar.smooth = NULL,
  tree.depth = 2, 
  n.trees.rf = 1000, 
  n.trees.boosting = 200, 
  B = 3, 
  Kfold = 5,
  error.maxNR = 1e-3, 
  max.iterNR = 150, 
  tune = c(0.5, 2),
  seed = NULL, 
  plot.gbmperf = TRUE
  )
```


### Arguments {.unlisted .unnumbered}


Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `pmcount()`) and "survival" (see `pmsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`score.method`          A vector of one or multiple methods to estimate the CATE score. Allowed values are: "boosting", "poisson", "twoReg", "contrastReg", "negBin" (count outcomes only), and "randomForest" (survival outcomes only).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`higher.y`              A logical value indicating whether higher (TRUE) or lower (FALSE) values of the outcome are more desirable. Default is TRUE.
`prop.cutoff`           A vector of numerical values (in (0, 1]) specifying percentiles of the estimated log CATE scores to define nested subgroups. Each element represents the cutoff to separate observations in nested subgroups (below vs above cutoff). The length of `prop.cutoff` is the number of nested subgroups. An equally-spaced sequence of proportions ending with 1 is recommended. Default is `seq(0.5, 1, length = 6)`.
`prop.multi`            A vector of numerical values (in [0, 1]) specifying percentiles of the estimated log CATE scores to define mutually exclusive subgroups. It should start with 0, end with 1, and be of `length(prop.multi) > 2`. Each element represents the cutoff to separate the observations into `length(prop.multi) - 1` mutually exclusive subgroups. Default is `c(0, 1/3, 2/3, 1)`.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.

Additional arguments            Description
------------------------        ------------------
`ipcw.method`                   A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`initial.predictor.method`      A character vector for the method used to get initial outcome predictions conditional on the covariates specified in `cate.model`. Only applies when `score.method` includes "twoReg" or "contrastReg". Allowed values include one of "randomForest" (survival outcomes only), "boosting", "logistic" (survival outcomes only, fast), "poisson" (count outcomes only, fast), and "gam" (count outcomes only). Default is NULL, which assigns "boosting" for count outcomes and "randomForest" for survival outcomes.
`xvar.smooth`                   A vector of characters indicating the name of the variables used as the smooth terms if `initial.predictor.method` = "gam". The variables must be selected from the variables listed in `cate.model`. Only applies for count outcomes. Default is NULL, which uses all variables in `cate.model`.
`tree.depth`                    A positive integer specifying the depth of individual trees in boosting (usually 2-3). Used only if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 2.
`n.trees.rf`                    A positive integer specifying the maximum number of trees in random forest. Used if `score.method` = "ranfomForest" or if `initial.predictor.method` = "randomForest" with `score.method` = "twoReg" or "contrastReg". Only applies for survival outcomes. Default is 1000.
`n.trees.boosting`              A positive integer specifying the maximum number of trees in boosting (usually 100-1000). Used if `score.method` = "boosting" or if `initial.predictor.method` = "boosting" with `score.method` = "twoReg" or "contrastReg". Default is 200.
`B`                             A positive integer specifying the number of time cross-fitting is repeated in `score.method` = "twoReg" and "contrastReg". Default is 3.
`Kfold`                         A positive integer specifying the number of folds used in cross-fitting to partition the data in `score.method` = "twoReg" and "contrastReg". Default is 5.
`error.maxNR`                   A numerical value > 0 indicating the minimum value of the mean absolute error in Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 0.001.
`max.iterNR`                    A positive integer indicating the maximum number of iterations in the Newton Raphson algorithm. Used only if `score.method` = "contrastReg". Default is 150.
`tune`                          A vector of 2 numerical values > 0 specifying tuning parameters for the Newton Raphson algorithm. `tune[1]` is the step size, `tune[2]` specifies a quantity to be added to diagonal of the slope matrix to prevent singularity. Used only if `score.method` = "contrastReg". Default is `c(0.5, 2)`.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`plot.gbmperf`                  A logical value indicating whether to plot the performance measures in boosting. Used only if `score.method` = "boosting" or if `score.method` = "twoReg" or "contrastReg" and `initial.predictor.method` = "boosting". Default is TRUE.


### Value {.unlisted .unnumbered}

Returns a list containing the following components:

* **ate.randomForest**: A vector of numerical values of length `prop.cutoff` containing the estimated ATE in nested subgroups (defined by `prop.cutoff`) constructed based on the estimated CATE score with random forest. Only provided if `score.method` includes "randomForest".

* **ate.boosting**: Same as `$ate.randomForest`, but with the nested subgroups based the estimated CATE score with boosting. Only provided if `score.method` includes "boosting".

* **ate.poisson**: Same as `$ate.randomForest`, but with the nested subgroups based the estimated CATE score with poisson regression. Only provided if `score.method` includes "negBin".

* **ate.twoReg**: Same as `$ate.randomForest`, but with the nested subgroups based the estimated CATE score with two regressions. Only provided if `score.method` includes "twoReg".

* **ate.contrastReg**: Same as `$ate.randomForest`, but with the nested subgroups based the estimated CATE score with contrast regression. Only provided if `score.method` includes "contrastReg".

* **hr.randomForest**: A vector of numerical values of length `prop.cutoff` containing the adjusted hazard ratio in nested subgroups (defined by `prop.cutoff`) constructed based on the estimated CATE scores with random forest method. Only provided if `score.method` includes "randomForest".

* **hr.boosting**: Same as `$hr.randomForest`, but with the nested subgroups based the estimated CATE score with boosting. Only provided if `score.method` includes "boosting".

* **hr.poisson**: Same as `$hr.randomForest`, but with the nested subgroups based the estimated CATE score with poisson regression. Only provided if `score.method` includes "negBin".

* **hr.twoReg**: Same as `$hr.randomForest`, but with the nested subgroups based the estimated CATE score with two regressions. Only provided if `score.method` includes "twoReg".

* **hr.contrastReg**: Same as `$hr.randomForest`, but with the nested subgroups based the estimated CATE score with contrast regression. Only provided if `score.method` includes "contrastReg".

* **score.poisson**: A vector of numerical values of length n (number of observations in `data`) containing the estimated log-CATE score according to the Poisson regression. Only provided if `score.method` includes "poisson".

* **score.boosting**: Same as `$score.poisson`, but with estimated log-CATE score according to boosting. Only provided if `score.method` includes "boosting".

* **score.twoReg**: Same as `$score.poisson`, but with estimated log-CATE score according to two regressions. Only provided if `score.method` includes "twoReg".

* **score.contrastReg**: Same as `$score.poisson`, but with estimated log-CATE score according to contrast regression. Only provided if `score.method` includes "contrastReg".

* **score.negBin**: Same as `$score.poisson`, but with estimated log-CATE score according to negative binomial regression. Only provided if `score.method` includes "negBin".

* **fit**: Additional details on model fitting if `score.method` includes "boosting" or "contrastReg":

    * **result.randomForest**: Details on the random forest model fitted to observations with treatment = 0 (\$fit0.rf) and to observations with treatment = 1 (\$fit1.rf). Only provided if `score.method` includes "randomForest".

    * **result.boosting**: Details on the boosting model fitted to observations with treatment = 0 (\$fit0.gbm) and to observations with treatment = 1 (\$fit1.gbm). Only provided if `score.method` includes "boosting".
    
    * **result.contrastReg$sigma.contrastReg**: Variance-covariance matrix of the estimated log-CATE coefficients in contrast regression. Only provided if `score.method` includes "contrastReg".

* **coefficients**: A data frame with the coefficients of the estimated log-CATE score by `score.method`. The data frame has number of rows equal to the number of covariates in `cate.model` and number of columns equal to length(`score.method`). If `score.method` includes "contrastReg", the data frame has an additional column containing the standard errors of the coefficients estimated with contrast regression. "randomForest" and "boosting" do not have coefficient results because tree-based methods typically do not express the log-CATE as a linear combination of coefficients and covariates.

### Details {.unlisted .unnumbered}

The CATE score represents an individual-level treatment effect for survival data, estimated with random forest, boosting, Poisson regression, and the doubly robust estimator (two regressions, @yadlowsky2020estimation) applied separately by treatment group or with the other doubly robust estimators (contrast regression, @yadlowsky2020estimation) applied to the entire data set.S

`pm()` provides the coefficients of the CATE score for each scoring method requested through `score.method`. Currently, contrast regression is the only method which allows for inference of the CATE coefficients by providing standard errors of the coefficients. The coefficients can be used to learn the effect size of each variable and predict the CATE score for a new observation.

`pm()` also provides predictions of the CATE score for each observation in the data set, for each scoring method. The predictions allow ranking the observations from high potential responders to the treatment to low or standard responders.

The estimated ATE among nested subgroups of high responders are also provided by scoring method. Note that the ATEs in `pm()` are derived based on the CATE score which is estimated using the entire data sample. Therefore, overfitting may be an issue. `cv()` is more suitable to inspect the estimated ATEs across scoring methods as it implements internal CV to reduce optimism.

## `dr.inference()`

### Description {.unlisted .unnumbered}

Doubly robust estimator of the average treatment effect between two treatments, which is the rate ratio for count outcomes and the restricted mean time lost ratio for survival outcomes. Bootstrap is used for inference.

```{r drinf, eval = F, echo = T}
dr.inference(
  response, 
  cate.model, 
  ps.model, 
  data,
  ipcw.model = NULL, 
  followup.time = NULL, 
  tau0 = NULL, 
  surv.min = 0.025, 
  ipcw.method = "breslow",
  ps.method = "glm", 
  minPS = 0.01, 
  maxPS = 0.99, 
  interactions = TRUE,
  n.boot = 500, 
  seed = NULL, 
  verbose = 1, 
  plot.boot = FALSE
  )
```

### Arguments {.unlisted .unnumbered}

Main arguments          Description
---------------         ------------
`response`              A string describing the type of outcome in the data. Allowed values include "count" (see `pmcount()`) and "survival" (see `pmsurv()`).
`cate.model`            A formula describing the outcome model to be fitted.The outcome must appear on the left-hand side. For survival outcomes, a `Surv` object must be used to describe the outcome.
`ps.model`              A formula describing the propensity score (PS) model to be fitted. The treatment must appear on the left-hand side. The treatment must be a numeric vector coded as 0/1. If data are from a randomized controlled trial, specify `ps.model = ~1` as an intercept-only model.
`data`                  A data frame containing the variables in the outcome, propensity score, and inverse probability of censoring models (if specified); a data frame with `n` rows (1 row per observation).
`ipcw.model`            A formula describing the inverse probability of censoring weighting (IPCW) model to be fitted. The left-hand side must be empty. Only applies for survival outcomes. Default is NULL, which corresponds to specifying the IPCW with the same covariates as the outcome model `cate.model`, plus the treatment.
`followup.time`         A column name in `data` specifying the maximum follow-up time, interpreted as the potential censoring time. Only applies for survival outcomes. Default is NULL, which corresponds to unknown potential censoring time.
`tau0`                  The truncation time for defining restricted mean time lost. Only applies for survival outcomes. Default is NULL, which corresponds to setting the truncation time as the maximum survival time in the data.
`ps.method`             A character value for the method to estimate the propensity score. Allowed values include one of: "glm" for logistic regression with main effects only (default), or "lasso" for a logistic regression with main effects and LASSO penalization on two-way interactions (added to the model if interactions are not specified in `ps.model`. Relevant only when `ps.model` has more than one variable.

Additional arguments            Description
------------------------        ------------------
`ipcw.method`                   A character value for the censoring model. Only applies for survival outcomes. Allowed values are: "breslow" (Cox regression with Breslow estimator of the baseline survivor function), "aft (exponential)", "aft (weibull)", "aft (lognormal)" or "aft (loglogistic)" (accelerated failure time model with different distributions for y variable). Default is "breslow".
`surv.min`                      Lower truncation limit for the probability of being censored. It must be a positive value and should be chosen close to 0. Only applies for survival outcomes. Default is 0.025.
`minPS`                         A numerical value (in [0, 1]) below which estimated propensity scores should be truncated. Default is 0.01.
`maxPS`                         A numerical value (in (0, 1]) above which estimated propensity scores should be truncated. Must be strictly greater than `minPS`. Default is 0.99.
`interactions`                  A logical value indicating whether the outcome model should assume interactions
x and trt. Applies only to count outcomes. If TRUE, interactions will be assumed only if at least 10 patients received each treatment option. Default is TRUE.
`n.boot`                        A numeric value indicating the number of bootstrap samples used. Default is 500.
`seed`                          An optional integer specifying an initial randomization seed for reproducibility. Default is NULL, corresponding to no seed.
`verbose`                       An integer value indicating whether intermediate progress messages and histograms should be printed. `1` indicates messages are printed and `0` otherwise. Default is `1`.
`plot.boot`                     A logical value indicating whether histograms of the bootstrapped log(rate ratio) (for count outcomes) log(restricted mean time lost ratio) (for survival outcomes) should be produced at every `n.boot`/10-th iteration and whether the final histogram should be outputted. This argument is only taken into account if `verbose` = 1. Default is FALSE.

### Value {.unlisted .unnumbered}

Return a list of 6 elements:

* **rmst1**: A vector of numeric values of the estimated RMST, bootstrap standard error, lower and upper limits of 95% confidence interval, and the p-value in the group trt=1.

* **rmst0**: A vector of numeric values of the estimated RMST, bootstrap standard error, lower and upper limits of 95% confidence interval, and the p-value in the group trt=0.

* **log.rmtl.ratio**: A vector of numeric values of the estimated log RMTL ratio of trt=1 over trt=0, bootstrap standard error, lower and upper limits of 95% confidence interval, and the p-value.

* **log.hazard.ratio**: A vector of numeric values of the estimated adjusted log hazard ratio of trt=1 over trt=0, bootstrap standard error, lower and upper limits of 95% confidence interval, and the p-value.

* **warning**: A warning message produced if the treatment variable was not coded as 0/1. The key to map the original coding of the variable to a 0/1 key is displayed in the warning to facilitate the interpretation of the remaining of the output.

* **plot**: If `plot.boot` is TRUE, a histogram displaying the distribution of the bootstrapped rmst1, rmst0, log.rmtl.ratio and log.hazard.ratio. The red vertical reference line in the histogram represents the estimates.

### Details {.unlisted .unnumbered}

This helper function estimates the average treatment effect (ATE) for survival data between two treatment groups in a given dataset. The ATE is estimated with a doubly robust estimator that accounts for imbalances in covariate distributions between the two treatment groups with inverse probability treatment and censoring weighting. 

For survival outcomes, the estimated ATE is the estimated by RMTL ratio between treatment 1 versus treatment 0. The log-transformed ATEs and log-transformed adjusted hazard ratios are returned, as well as the estimated RMST in either treatment group. The variability of the estimated RMTL ratio is calculated using bootstrap. Additional outputs include standard error of the log RMTL ratio, 95% confidence interval, p-value, and a histogram of the bootstrap estimates.

# Theoretical details {#theodetail}
Assume that the following data are recorded for each of $n$ observations:

* $R$ is a binary treatment taking value 0 or 1. 
* $\boldsymbol{X}$ is a vector of $p$ baseline covariates.
* $T$ is a survival time.
* $C$ is a censoring time.
* $Y$ is the minimum between $T$ and $C$.
* $\delta$ is an indicator taking value 1 if $Y = T$ and 0 otherwise.
* $\tau$ is a truncation time for restricted mean time lost.

The objective is to estimate the ratio-based CATE score defined as 

$$CATE(\boldsymbol{x})=\text{log}\left(\frac{\mathbb{E}[\tau - (T^{(1)} \wedge\tau)|\boldsymbol{X}=\boldsymbol{x}]}{\mathbb{E}[\tau - (T^{(0)} \wedge\tau)|\boldsymbol{X}=\boldsymbol{x}]}\right)$$
where $T^{(r)}$ is the potential survival time if the patient received the treatment $r \in \{0,1\}$. $CATE(\boldsymbol{x})$ is interpreted as the individualized logarithm restricted mean time lost (RMTL) ratio of treatment 1 over treatment 0 conditional on the baseline covariates. 

The package offers 5 methods to estimate the CATE score: Poisson regression, random forest, boosting, two regressions, and contrast regression.

## Poisson

1. Estimate the conditional mean RMTL given baseline covariates separately in each treatment group (i.e., $\text{log}(\mathbb{E}[\tau - T\wedge\tau|\boldsymbol{x}, r])=\beta_r \boldsymbol{\tilde x}$ for $r \in \{0,1\}$ where $\boldsymbol{\tilde x}$ is the $x$ with an intercept) with Poisson regression weighted with IPCW. Denote the prediction as $\hat Y^{(r)}(\boldsymbol{x})=\text{exp}(\hat \beta_r \boldsymbol{\tilde x})$.

2. The CATE score with Poisson is the plug-in estimator

$$\widehat{CATE}_{Poisson}(\boldsymbol{x})=\text{log}\left(\frac{\hat Y^{(1)}(\boldsymbol{x})}{\hat Y^{(0)}(\boldsymbol{x})}\right) = (\hat \beta_1 - \hat \beta_0) \boldsymbol{\tilde x}$$

## Boosting

1. Estimate the conditional mean RMTL given baseline covariates separately in each treatment group (i.e., $\mathbb{E}[Y^{(r)}|\boldsymbol{x}]$ for $r \in \{0,1\}$) with Poisson-based gradient boosting regression method weighted with IPCW. Denote the prediction as $\hat Y^{(r)}(\boldsymbol{x})$.

    * The number of trees is specificed with the argument `n.trees.boosting`. Default is 200.
    * The depth of trees is specified with the argument `tree.depth`. Default is 2.
    
2. 	The CATE score with boosting is the plug-in estimator

$$\widehat{CATE}_{boosting}(\boldsymbol{x})=\text{log}\left(\frac{\hat Y^{(1)}(\boldsymbol{x})}{\hat Y^{(0)}(\boldsymbol{x})}\right)$$

## Random forest

1. Estimate the conditional mean RMTL given baseline covariates separately in each treatment group (i.e., $\mathbb{E}[Y^{(r)}|\boldsymbol{x}]$ for $r \in \{0,1\}$) with survival random forest. Denote the prediction as $\hat Y^{(r)}(\boldsymbol{x})$.

    * The number of trees in boosting is selected via CV with a maximum number of trees specificed with the argument `n.trees.rf`. Default is 1,000.
    * The base learners are regression trees with depth specified with the argument `tree.depth`. Default is 2.
    
2. 	The CATE score with boosting is the plug-in estimator

$$\widehat{CATE}_{boosting}(\boldsymbol{x})=\text{log}\left(\frac{\hat Y^{(1)}(\boldsymbol{x})}{\hat Y^{(0)}(\boldsymbol{x})}\right)$$

## Two regressions

1. Randomly separate the data $D$ into $K$ (`Kfold`) non-overlapping parts of approximately equal sizes, $D_1, \dots, D_K$.
2. For each fold $k=1,\dots,K$, and separately by treatment arm $r \in \{0,1\}$:

    2.1 Estimate the conditional mean RMTL given baseline covariates with the
    Poisson-based gradient boosting regression method (`initial.predictor.method = "boosting"`) based on observations without the kth fold, $D_{-k}$, and denote the prediction as $\hat Y_{-k}^{(r)}(\boldsymbol{x})$. This is the initial nonparametric prediction of the potential outcome. Other methods can be used to generate an initial prediction (see `initial.predictor.method` argument).
    
    2.2 Estimate the propensity score model based on $D_{-k}$. Denote the estimated PS as $\hat \pi_{-k}(\boldsymbol{x})$ and estimate the weights $\hat W_{-k}(r)=r\frac{R}{\hat \pi_{-k}(\boldsymbol{x})}+(1-r)\frac{(1-R)}{1-\hat \pi_{-k}(\boldsymbol{x})}$ with $R$ denoting the treatment received.
    
    2.3 Estimate the IPCW:
    
    $$\hat L(r,y) = \frac{\delta+(1-\delta)I(y^{(r)}\geq\tau)}{\hat K_{C^{(r)}}(T \wedge \tau|x)}$$
    
    where $\hat K_{C^{(r)}}(T \wedge \tau|x)$ is a consistent estimator of the survival function of the censoring time given the covariate $x$, for example, using a Cox model and the Breslow estimator for the cumulative baseline hazard function (`ipcw.method = "breslow"`).
    
    2.4 Solve the following weighted estimating equation by fitting a Poisson regression with $\tau - (T\wedge\tau)$ as the response, $\text{log}(\hat Y_{-k}^{(r)}(\boldsymbol{x}))$ and $x$ as the covariates, and $\hat K(r,y)\times\hat W_{-k}(r)$ as weight:
    
    $$S(\alpha_{rk}, \boldsymbol{\gamma_{rk}})=\sum_{i \in D_{-k}} \hat K(r,y) \hat W_{-k}(r) \left((\tau- T\wedge\tau) - \text{exp}\left(\alpha_{rk}\text{log}
    \left(\hat Y_{-k}^{(r)}(\boldsymbol{x})\right)+\boldsymbol{\gamma_{rk}^T}\boldsymbol{\tilde x}\right)\right)=0$$
    
3. Solve the following doubly robust estimating equation by fitting a Poisson regression with $\text{exp}\left(\hat\alpha_{rk}\text{log}\left(\hat Y_{-k}^{(r)}(\boldsymbol{x})\right)+\boldsymbol{\hat\gamma_{rk}^T\boldsymbol{\tilde x}}\right)$ as the response, $\boldsymbol{x}$ as the covariates, and no offset or weight:
$$S(\boldsymbol{\beta_r})=\sum_{k=1}^K \sum_{i \in D_{k}}\boldsymbol{\tilde x}\left(\text{exp}\left(\hat\alpha_{rk}\text{log}\left(\hat Y_{-k}^{(r)}(\boldsymbol{x})\right)+\boldsymbol{\hat\gamma_{rk}^T\boldsymbol{\tilde x}}\right)-\text{exp}(\boldsymbol{\beta_r^T\tilde x})\right)=0$$
Denote the estimator as $\boldsymbol{\hat \beta_r}$. 

4. Repeat steps 1-3 with $B$ bootstrap samples (`B`) and denote the estimator $\boldsymbol{\hat \beta_{rb}}$ in the $b$ sample. The final estimator $\boldsymbol{\hat \beta_r}$ is the mean of the $\boldsymbol{\hat \beta_{rb}}$.

5. The CATE score with two regression is  

$$\widehat{CATE}_{tworeg}(\boldsymbol{x})=(\boldsymbol{\hat \beta_1} - \boldsymbol{\hat \beta_0})^T\boldsymbol{\tilde x}$$

## Contrast regression

1. Randomly separate the data $D$ into $K$ (`Kfold`) non-overlapping parts of approximately equal sizes, $D_1, \dots, D_K$.
2. For each fold $k=1,\dots,K$, and separately by treatment arm $r \in \{0,1\}$:

    2.1 Estimate the conditional mean RMTL given baseline covariates with the
    Poisson-based gradient boosting regression method (`initial.predictor.method = "boosting"`) based on observations without the kth fold, $D_{-k}$, and denote the prediction as $\hat Y_{-k}^{(r)}(\boldsymbol{x})$. This is the initial nonparametric prediction of the potential outcome. Other methods can be used to generate an initial prediction (see `initial.predictor.method` argument).
    
    2.2 Estimate the propensity score model based on $D_{-k}$. Denote the estimated PS as $\hat \pi_{-k}(\boldsymbol{x})$.
    
    2.3 Estimate the IPCW:
    
    $$\hat L(r,y) = \frac{\delta+(1-\delta)I(y^{(r)}\geq\tau)}{\hat K_{C^{(r)}}(T \wedge \tau|x)}$$
    
    where $\hat K_{C^{(r)}}(T \wedge \tau|x)$ is a consistent estimator of the survival function of the censoring time given the covariate $x$, for example, using a Cox model and the Breslow estimator for the cumulative baseline hazard function (`ipcw.method = "breslow"`).
    
3. Solve the following doubly robust estimating equation by Newton-Raphson method or using a L2-norm score method if the former fails to converge:
$$\begin{aligned}
S(\boldsymbol{\delta})&=\sum_{k=1}^K \sum_{i \in D_{k}} \hat L(r,y) \boldsymbol{\tilde x}\Bigg[\frac{R\left\{(\tau - T\wedge\tau)-\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat Y_{-k}^{(0)}(\boldsymbol{x})\right\}(1-\hat\pi_{-k}(\boldsymbol{x}))}{\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})+1-\hat\pi_{-k}(\boldsymbol{x})}\\
&-\frac{(1-R)\left\{(\tau - T\wedge\tau)-\hat Y_{-k}^{(0)}(\boldsymbol{ x}) \right\}\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})}{\text{exp}(\boldsymbol{\delta^T}\boldsymbol{\tilde x})\hat\pi_{-k}(\boldsymbol{x})+1-\hat\pi_{-k}(\boldsymbol{x})}\Bigg]=0
\end{aligned}$$
Denote the estimator as $\boldsymbol{\hat\delta}$.

4. Repeat steps 1-3 with $B$ bootstrap samples (`B`) and denote the estimator $\boldsymbol{\hat \delta_b}$ in the $b$ sample. The final estimator $\boldsymbol{\hat \delta}$ is the mean of the $\boldsymbol{\hat \delta_b}$.

5. The CATE score with contrast regression is  

$$\widehat{CATE}_{contrastreg}(\boldsymbol{x})=\boldsymbol{\hat \delta^T\tilde x}$$

## Validation curves and the ABC statistics {#ABCdetails}
The ABC statistic represents the area between the validation curve and the ATE. For a single CV iteration and a certain CATE score method, it is implemented as following in the training and validation sets separately:

**Step 1**. Calculate the ATE in the training or validation sets.

**Step 2**. Calculate the ATE in 100 nested subgroups and derive the corresponding validation curve. Subgroups are defined with 100 equally-spaced proportions from `min(prop.cutoff)` to `max(prop.cutoff)` to ensure that enough data points are available to build the validation curve.

**Step 3**. The ABC is calculated with `auc()` from the MESS R package using the natural cubic spline interpolation, which calculates the area between the horizontal line with y-intercept at the ATE calculated in **step 1** (*y*) and the validation curve calculated in **step 2** (*x*) over the range [`min(prop.cutoff)`, `max(prop.cutoff)`].


The function `plot()` allows the user combining validation curves from 2 or more CV iterations (i.e., `cv.n > 1`). There are 2 ways to combine the validation curves:

1. The option `combine ="median"` takes the median of the ATEs across all CV iterations in **step 1** and the median of the ATEs in the 100 nested subgroups in **step 2**. 

2. The option `combine ="mean"` takes the mean of the ATEs across all CV iterations in **step 1** and the mean of the ATEs in the 100 nested subgroups in **step 2**. 

In either case, the ABC calculations are carried out as in **step 3** with the resulting *x* and *y*.


The figure below explains how the ABC is calculated with a simple schema. The ABC calculations are such that larger positive ABC values always indicate more treatment effect heterogeneity. This is implemented by considering separately the cases when larger or smaller outcomes are preferred.

* If smaller survival outcomes are preferred (`higher.y = FALSE`, e.g., time to a positive event like recovery), a validation curve above the ATE line which decreases towards it is synonym with treatment effect heterogeneity (top left figure). However, sections of the validation curve below the ATE line indicate inability to capture treatment effect heterogeneity (bottom left figure). Hence, the ABC is defined by subtracting the areas below the ATE line from the areas above the ATE line such that larger positive ABC are preferred. 

* If larger survival outcomes are preferred (`higher.y = TRUE`, e.g., time to a negative event like symptom onset), a validation curve (in blue) below the ATE line (dashed) which increases towards it is synonym with treatment effect heterogeneity (top right figure). However, sections of the validation curve above the ATE line indicate inability to capture treatment effect heterogeneity (bottom right figure). Hence, the ABC is defined by subtracting the areas above the ATE line (in red) from the areas below the ATE line (in green) such that larger positive ABC are preferred.


![Figure. ABC calculation examples in relation with `higher.y` argument in `cv()` and `pm()`. Validation curves are represented with a blue line and the dashed line is the ATE.](assets/ABCexample_survival.png)


# References
